<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Internal CLI - AbstractCore</title>
    <meta name="description" content="Interactive CLI for testing and exploring AbstractCore providers, tools, media, and token controls.">
    <link rel="icon" type="image/svg+xml" href="../assets/logo.svg">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/css/main.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">

    <!-- Navbar Component -->
    <script src="../assets/js/navbar-component.js"></script>
</head>
<body>
    <!-- Navigation -->
    <div class="navbar-placeholder"></div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            createNavbar({
                basePath: '',
                menuItems: [
                    { text: 'Features', href: '/docs/capabilities.html' },
                    { text: 'Quick Start', href: '/docs/getting-started.html' },
                    { text: 'Documentation', href: '/#docs' },
                    { text: 'Examples', href: '/docs/examples.html' },
                    {
                        text: 'GitHub',
                        href: 'https://github.com/lpalbou/abstractcore',
                        target: '_blank',
                        icon: 'github'
                    },
                    {
                        text: 'PyPI',
                        href: 'https://pypi.org/project/abstractcore/',
                        target: '_blank',
                        icon: 'pypi'
                    }
                ]
            });
        });
    </script>

    <!-- Main Content -->
    <main style="padding-top: 5rem;">
        <div class="container" style="max-width: 1300px;">
            <div class="doc-header" style="margin-bottom: 3rem;">
                <h1 style="font-size: 2.5rem; margin-bottom: 1rem;">Internal CLI</h1>
                <p style="font-size: 1.25rem; color: var(--text-secondary);">
                    A lightweight interactive CLI for testing and exploring providers, tools, media, and token controls.
                    This is AbstractCore’s internal chat CLI—not an external agentic CLI.
                </p>
            </div>

            <div style="background: var(--info-bg); border: 1px solid var(--info-text); padding: 1.5rem; border-radius: 0.75rem; margin-bottom: 3rem;">
                <p style="margin: 0; color: var(--info-text);">
                    <strong>Using Codex / Gemini CLI / Crush?</strong>
                    Use the OpenAI-compatible server instead: see the <a href="server.html" style="color: var(--info-text); text-decoration: underline; font-weight: 600;">HTTP Server Guide</a>.
                </p>
            </div>

            <!-- Table of Contents -->
            <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin-bottom: 3rem;">
                <h2 style="margin: 0 0 1rem 0;">Table of Contents</h2>
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 0.75rem;">
                    <div>
                        <a href="#quick-start" style="display: block; padding: 0.4rem 0; color: var(--primary-color);">Quick Start</a>
                        <a href="#token-controls" style="display: block; padding: 0.4rem 0; color: var(--primary-color);">Token Controls</a>
                        <a href="#thinking" style="display: block; padding: 0.4rem 0; color: var(--primary-color);">Thinking / Reasoning</a>
                    </div>
                    <div>
                        <a href="#commands" style="display: block; padding: 0.4rem 0; color: var(--primary-color);">Built-in Commands</a>
                        <a href="#media" style="display: block; padding: 0.4rem 0; color: var(--primary-color);">Media Attachments</a>
                        <a href="#async-demo" style="display: block; padding: 0.4rem 0; color: var(--primary-color);">Async Demo (Educational)</a>
                    </div>
                </div>
            </div>

            <div class="doc-content">
                <section id="quick-start">
                    <h2>Quick Start</h2>
                    <p>The internal CLI is installed as <code>abstractcore-chat</code>.</p>

                    <div class="code-block">
                        <pre><code class="language-bash"># Local provider (Ollama)
abstractcore-chat --provider ollama --model qwen3:4b-instruct

# Cloud providers
abstractcore-chat --provider openai --model gpt-4o-mini
abstractcore-chat --provider anthropic --model claude-haiku-4-5

# OpenAI-compatible local servers
# Note: include /v1 in the base URL.
abstractcore-chat --provider lmstudio --model qwen/qwen3-4b-2507 --base-url http://localhost:1234/v1
abstractcore-chat --provider openai-compatible --model local-model --base-url http://localhost:1234/v1

# Streaming
abstractcore-chat --provider ollama --model qwen3:4b-instruct --stream</code></pre>
                    </div>

                    <div style="background: var(--background-tertiary); padding: 1.25rem; border-radius: 0.75rem; margin: 1rem 0;">
                        <p style="margin: 0;">
                            <strong>Tip:</strong> <code>python -m abstractcore.utils.cli ...</code> is equivalent if you prefer module execution.
                        </p>
                    </div>

                    <h3>API keys</h3>
                    <p>Cloud providers require API keys in your environment:</p>
                    <ul>
                        <li>OpenAI: <code>OPENAI_API_KEY</code></li>
                        <li>Anthropic: <code>ANTHROPIC_API_KEY</code></li>
                        <li>OpenRouter: <code>OPENROUTER_API_KEY</code></li>
                    </ul>
                </section>

                <section id="token-controls" style="margin-top: 3rem;">
                    <h2>Token Controls</h2>
                    <p>Set token budgets at startup or adjust them inside the REPL.</p>

                    <div class="code-block">
                        <pre><code class="language-bash"># Startup flags
abstractcore-chat --provider openai --model gpt-4o-mini --max-tokens 16384 --max-output-tokens 1024</code></pre>
                    </div>

                    <div class="code-block">
                        <pre><code class="language-bash"># In the REPL
/max-tokens 16384
/max-output-tokens 1024
/max-tokens auto
/max-output-tokens auto</code></pre>
                    </div>
                </section>

                <section id="thinking" style="margin-top: 3rem;">
                    <h2>Thinking / Reasoning</h2>
                    <p>Toggle unified thinking/reasoning mode (best-effort across providers/models):</p>

                    <div class="code-block">
                        <pre><code class="language-bash">/thinking auto
/thinking on
/thinking off
/thinking low
/thinking medium
/thinking high</code></pre>
                    </div>

                    <p>Control whether reasoning (when available) is displayed separately:</p>

                    <div class="code-block">
                        <pre><code class="language-bash">/show-reasoning auto
/show-reasoning on
/show-reasoning off</code></pre>
                    </div>
                </section>

                <section id="commands" style="margin-top: 3rem;">
                    <h2>Built-in Commands</h2>
                    <p>A few useful commands shipped with the CLI:</p>
                    <ul>
                        <li><code>/compact</code> — compacts chat history (fast local summarizer model)</li>
                        <li><code>/facts [file]</code> — extract facts as triples (optionally save JSON-LD)</li>
                        <li><code>/judge</code> — evaluate discussion quality (LLM-as-a-judge demonstrator)</li>
                        <li><code>/intent [participant]</code> — intent analysis (optionally per participant)</li>
                    </ul>
                </section>

                <section id="media" style="margin-top: 3rem;">
                    <h2>Media Attachments (<code>@filename</code>)</h2>
                    <p>Attach files directly in your prompt using <code>@path/to/file</code> (requires media extras):</p>

                    <div class="code-block">
                        <pre><code class="language-bash">pip install "abstractcore[media]"</code></pre>
                    </div>

                    <div class="code-block">
                        <pre><code class="language-bash"># Image analysis
abstractcore-chat --provider openai --model gpt-4o --prompt "What's in @photo.jpg?"

# PDF document analysis
abstractcore-chat --provider anthropic --model claude-haiku-4-5 --prompt "Summarize @report.pdf"

# Office documents and data files
abstractcore-chat --provider openai --model gpt-4o --prompt "Extract action items from @slides.pptx"
abstractcore-chat --provider openai --model gpt-4o --prompt "Analyze @spreadsheet.xlsx"
abstractcore-chat --provider openai --model gpt-4o-mini --prompt "Spot anomalies in @metrics.csv"</code></pre>
                    </div>

                    <h3>Supported file types</h3>
                    <ul>
                        <li><strong>Images:</strong> PNG, JPEG, GIF, WEBP, BMP, TIFF</li>
                        <li><strong>Documents:</strong> PDF, DOCX, XLSX, PPTX</li>
                        <li><strong>Data/Text:</strong> CSV, TSV, TXT, MD, JSON, XML</li>
                    </ul>
                </section>

                <section id="async-demo" style="margin-top: 3rem;">
                    <h2>Async CLI Demo (Educational)</h2>
                    <p>AbstractCore includes an educational async CLI demo to learn async patterns. This is for learning, not production.</p>

                    <div class="code-block">
                        <pre><code class="language-bash">python examples/async_cli_demo.py --provider ollama --model qwen3:4b
python examples/async_cli_demo.py --provider lmstudio --model qwen/qwen3-vl-30b --stream</code></pre>
                    </div>
                </section>

                <!-- Related Documentation -->
                <div style="margin-top: 4rem; padding: 2rem; background: var(--background-secondary); border-radius: 0.75rem;">
                    <h2 style="margin: 0 0 1.5rem 0;">Related Documentation</h2>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem;">
                        <a href="apps.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">CLI Apps</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Summarizer, Extractor, Judge, Intent, DeepSearch</p>
                        </a>

                        <a href="token-management.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Token Management</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Unified budgets and validation</p>
                        </a>

                        <a href="media-handling-system.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Media Handling</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Images, PDFs, Office docs + fallback</p>
                        </a>

                        <a href="server.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">HTTP Server</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">OpenAI-compatible gateway for agentic CLIs</p>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
