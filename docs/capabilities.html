<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Capabilities - AbstractCore</title>
    <meta name="description" content="What AbstractCore can and cannot do. Understand when to use AbstractCore and when to look elsewhere.">
    <link rel="icon" type="image/x-icon" href="../assets/favicon.ico">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/css/main.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-brand">
                <a href="../index.html" class="brand-link">
                    <img src="../assets/logo.svg" alt="AbstractCore" class="brand-logo">
                    <span class="brand-text">AbstractCore</span>
                </a>
            </div>
            
            <div class="nav-menu" id="nav-menu">
                <a href="../index.html#features" class="nav-link">Features</a>
                <a href="../index.html#quickstart" class="nav-link">Quick Start</a>
                <a href="../index.html#docs" class="nav-link">Documentation</a>
                <a href="../index.html#examples" class="nav-link">Examples</a>
                <a href="https://github.com/lpalbou/AbstractCore" class="nav-link" target="_blank">
                    <svg class="github-icon" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                    </svg>
                    GitHub
                </a>
            </div>
            
            <div class="nav-toggle" id="nav-toggle">
                <span class="bar"></span>
                <span class="bar"></span>
                <span class="bar"></span>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main style="padding-top: 5rem;">
        <div class="container" style="max-width: 1000px;">
            <div class="doc-header" style="margin-bottom: 3rem;">
                <h1 style="font-size: 2.5rem; margin-bottom: 1rem;">AbstractCore Capabilities</h1>
                <p style="font-size: 1.25rem; color: var(--text-secondary);">
                    This document clearly explains what AbstractCore <strong>can and cannot do</strong>, 
                    helping you understand when to use it and when to look elsewhere.
                </p>
            </div>

            <div class="doc-content">
                <section>
                    <h2>What AbstractCore IS</h2>
                    <div style="background: linear-gradient(135deg, var(--primary-color), var(--secondary-color)); padding: 2rem; border-radius: 0.75rem; color: white; margin: 2rem 0;">
                        <p style="margin: 0; font-size: 1.125rem; font-weight: 500;">
                            AbstractCore is <strong>production-ready LLM infrastructure</strong>. 
                            It provides a unified, reliable interface to language models with essential features built-in.
                        </p>
                    </div>

                    <h3>Core Philosophy</h3>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem; margin: 2rem 0;">
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Infrastructure</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Not application logic</p>
                        </div>
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Reliability</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Over features</p>
                        </div>
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Simplicity</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Over complexity</p>
                        </div>
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Provider Agnostic</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Works everywhere</p>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>✅ What AbstractCore Does Exceptionally Well</h2>
                    
                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">1. Universal LLM Provider Interface</h3>
                        <p><strong>What it does</strong>: Provides identical APIs across all major LLM providers.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># Same code works with any provider
def ask_llm(provider_name, question):
    llm = create_llm(provider_name, model="default")
    return llm.generate(question)

# All of these work identically
ask_llm("openai", "What is Python?")
ask_llm("anthropic", "What is Python?")
ask_llm("ollama", "What is Python?")</code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: No other library provides truly universal tool calling, streaming, and structured output across all providers.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">2. Production-Grade Reliability</h3>
                        <p><strong>What it does</strong>: Handles failures gracefully with retry logic, circuit breakers, and comprehensive error handling.</p>
                        
                        <ul>
                            <li><strong>Automatic retries</strong> with exponential backoff for rate limits and network errors</li>
                            <li><strong>Circuit breakers</strong> prevent cascade failures when providers go down</li>
                            <li><strong>Smart error classification</strong> - retries recoverable errors, fails fast on auth errors</li>
                            <li><strong>Event system</strong> for monitoring and alerting</li>
                        </ul>
                        
                        <p><strong>Why it's exceptional</strong>: Built for production from day one, not research or prototypes.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">3. Universal Tool Calling</h3>
                        <p><strong>What it does</strong>: Tools work consistently across ALL providers, even those without native tool support.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python">from abstractllm import create_llm, tool

@tool
def get_weather(city: str) -> str:
    """Get weather for a city."""
    return f"Weather in {city}: 72°F, sunny"

# Works with providers that have native tool support
openai_response = openai_llm.generate("Weather in Paris?", tools=[get_weather])

# Also works with providers that don't (via intelligent prompting)
ollama_response = ollama_llm.generate("Weather in Paris?", tools=[get_weather])</code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: Most libraries only support OpenAI-style tools. AbstractCore makes ANY model work with tools.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">4. Tool Call Tag Rewriting for Agentic CLI Compatibility</h3>
                        <p><strong>What it does</strong>: Automatically rewrites tool call tags to match different agentic CLI requirements in real-time.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># Rewrite tool calls for different CLIs
llm = create_llm("openai", model="gpt-4o-mini")

# For Codex CLI (Qwen3 format)
response = llm.generate("Weather in Paris?", tools=tools, tool_call_tags="qwen3")
# Output: <|tool_call|>{"name": "get_weather", "arguments": {"location": "Paris"}}</|tool_call|>

# For Crush CLI (LLaMA3 format)  
response = llm.generate("Weather in Paris?", tools=tools, tool_call_tags="llama3")
# Output: <function_call>{"name": "get_weather", "arguments": {"location": "Paris"}}</function_call>

# For Gemini CLI (XML format)
response = llm.generate("Weather in Paris?", tools=tools, tool_call_tags="xml")
# Output: <tool_call>{"name": "get_weather", "arguments": {"location": "Paris"}}</tool_call></code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: Seamless compatibility with any agentic CLI without code changes.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">5. Structured Output with Automatic Retry</h3>
                        <p><strong>What it does</strong>: Gets typed Python objects from LLMs with automatic validation and retry on failures.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python">from pydantic import BaseModel

class Product(BaseModel):
    name: str
    price: float

# Automatically retries with error feedback if validation fails
product = llm.generate(
    "Extract: Gaming laptop for $1200",
    response_model=Product
)</code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: Built-in validation retry means higher success rates and less manual error handling.</p>
                    </div>
                </section>

                <section>
                    <h2>❌ What AbstractCore Does NOT Do</h2>
                    <p style="color: var(--text-secondary); margin-bottom: 2rem;">Understanding limitations is crucial for choosing the right tool.</p>
                    
                    <div style="background: #fee2e2; border: 1px solid #fecaca; padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: #dc2626;">1. RAG Pipelines (Use Specialized Tools)</h3>
                        <p><strong>What AbstractCore provides</strong>: Vector embeddings via <code>EmbeddingManager</code></p>
                        <p><strong>What it doesn't provide</strong>: Document chunking, vector databases, retrieval strategies</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># AbstractCore gives you this
from abstractllm.embeddings import EmbeddingManager
embedder = EmbeddingManager()
similarity = embedder.compute_similarity("query", "document")

# You need to build this yourself
def rag_pipeline(query, documents):
    # 1. Chunk documents - YOU implement
    # 2. Store in vector DB - YOU implement
    # 3. Retrieve relevant chunks - YOU implement
    # 4. Construct prompt - YOU implement
    return llm.generate(prompt)</code></pre>
                        </div>
                        
                        <p><strong>Better alternatives</strong>:</p>
                        <ul>
                            <li><strong><a href="https://github.com/run-llama/llama_index" target="_blank">LlamaIndex</a></strong> - Full RAG framework</li>
                            <li><strong><a href="https://github.com/langchain-ai/langchain" target="_blank">LangChain</a></strong> - RAG components and chains</li>
                        </ul>
                    </div>

                    <div style="background: #fee2e2; border: 1px solid #fecaca; padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: #dc2626;">2. Complex Agent Workflows (Use Agent Frameworks)</h3>
                        <p><strong>What AbstractCore provides</strong>: Single LLM calls with tool execution</p>
                        <p><strong>What it doesn't provide</strong>: Multi-step agent reasoning, planning, memory persistence</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># AbstractCore is great for this
response = llm.generate("What's 2+2?", tools=[calculator_tool])

# AbstractCore is NOT for this
def complex_agent():
    # 1. Plan multi-step solution - NOT provided
    # 2. Execute steps with memory - NOT provided
    # 3. Reflect and re-plan - NOT provided
    # 4. Persist agent state - NOT provided
    pass</code></pre>
                        </div>
                        
                        <p><strong>Better alternatives</strong>:</p>
                        <ul>
                            <li><strong><a href="https://github.com/lpalbou/AbstractAgent" target="_blank">AbstractAgent</a></strong> - Built on AbstractCore</li>
                            <li><strong><a href="https://github.com/langchain-ai/langgraph" target="_blank">LangGraph</a></strong> - Agent orchestration</li>
                            <li><strong><a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank">AutoGPT</a></strong> - Autonomous agents</li>
                        </ul>
                    </div>
                </section>

                <section>
                    <h2>When to Choose AbstractCore</h2>
                    
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin: 2rem 0;">
                        <div>
                            <h3 style="color: var(--secondary-color);">✅ Choose AbstractCore When You Need:</h3>
                            <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem;">
                                <ol>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Reliable LLM Infrastructure</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Production-ready error handling and retry logic</li>
                                            <li>Consistent interface across different providers</li>
                                            <li>Built-in monitoring and observability</li>
                                        </ul>
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Provider Flexibility</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Easy switching between OpenAI, Anthropic, Ollama, etc.</li>
                                            <li>Provider-agnostic code that runs anywhere</li>
                                            <li>Local and cloud provider support</li>
                                        </ul>
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Universal Tool Calling</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Tools that work across ALL providers</li>
                                            <li>Consistent tool execution regardless of native support</li>
                                            <li>Event-driven tool control and monitoring</li>
                                        </ul>
                                    </li>
                                </ol>
                            </div>
                        </div>
                        
                        <div>
                            <h3 style="color: #dc2626;">❌ Don't Choose AbstractCore When You Need:</h3>
                            <div style="background: #fee2e2; padding: 1.5rem; border-radius: 0.75rem;">
                                <ol>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Full RAG Frameworks</strong> → Use LlamaIndex or LangChain
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Complex Agent Workflows</strong> → Use AbstractAgent or LangGraph
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Advanced Memory Systems</strong> → Use AbstractMemory or Mem0
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Prompt Template Management</strong> → Use Jinja2 or LangChain Prompts
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Model Training/Fine-tuning</strong> → Use Transformers or Axolotl
                                    </li>
                                    <li>
                                        <strong>Multi-Agent Systems</strong> → Use CrewAI or AutoGen
                                    </li>
                                </ol>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Related Documentation -->
                <div style="margin-top: 4rem; padding: 2rem; background: var(--background-secondary); border-radius: 0.75rem;">
                    <h2 style="margin: 0 0 1.5rem 0;">Related Documentation</h2>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem;">
                        <a href="getting-started.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Getting Started</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">5-minute quick start guide</p>
                        </a>
                        
                        <a href="api-reference.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">API Reference</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Complete Python API documentation</p>
                        </a>
                        
                        <a href="tool-calling.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Tool Calling</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Universal tool system guide</p>
                        </a>
                        
                        <a href="examples.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Examples</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Real-world usage examples</p>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
