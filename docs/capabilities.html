<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Capabilities - AbstractCore</title>
    <meta name="description" content="What AbstractCore can and cannot do. Understand when to use AbstractCore and when to look elsewhere.">
    <link rel="icon" type="image/x-icon" href="../assets/favicon.ico">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/css/main.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    
    <!-- Navbar Component -->
    <script src="../assets/js/navbar-component.js"></script>
</head>
<body>
    <!-- Navigation -->
    <div class="navbar-placeholder"></div>
    
    <script>
        // Initialize navbar with docs-specific configuration
        document.addEventListener('DOMContentLoaded', function() {
            createNavbar({
                                basePath: '../',
                menuItems: [
                    { text: 'Features', href: 'capabilities.html' },
                    { text: 'Quick Start', href: 'getting-started.html' },
                    { text: 'Documentation', href: '../index.html#docs' },
                    { text: 'Examples', href: 'examples.html' },
                    {
                        text: 'GitHub',
                        href: 'https://github.com/lpalbou/AbstractCore',
                        target: '_blank',
                        icon: 'github'
                    },
                    {
                        text: 'PyPI',
                        href: 'https://pypi.org/project/abstractcore/',
                        target: '_blank',
                        icon: 'pypi'
                    }
                ]});
        });
    </script>

    <!-- Main Content -->
    <main style="padding-top: 5rem;">
        <div class="container" style="max-width: 1300px;">
            <div class="doc-header" style="margin-bottom: 3rem;">
                <h1 style="font-size: 2.5rem; margin-bottom: 1rem;">AbstractCore Capabilities</h1>
                <p style="font-size: 1.25rem; color: var(--text-secondary);">
                    This document clearly explains what AbstractCore <strong>can and cannot do</strong>, 
                    helping you understand when to use it and when to look elsewhere.
                </p>
            </div>

            <div class="doc-content">
                <section>
                    <h2>What AbstractCore IS</h2>
                    <div style="background: linear-gradient(135deg, var(--primary-color), var(--secondary-color)); padding: 2rem; border-radius: 0.75rem; color: white; margin: 2rem 0;">
                        <p style="margin: 0; font-size: 1.125rem; font-weight: 500;">
                            AbstractCore is <strong>production-ready LLM infrastructure</strong>. 
                            It provides a unified, reliable interface to language models with essential features built-in.
                        </p>
                    </div>

                    <h3>Core Philosophy</h3>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem; margin: 2rem 0;">
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Infrastructure</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Not application logic</p>
                        </div>
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Reliability</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Over features</p>
                        </div>
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Simplicity</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Over complexity</p>
                        </div>
                        <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; text-align: center;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Provider Agnostic</h4>
                            <p style="margin: 0; font-size: 0.875rem;">Works everywhere</p>
                        </div>
                    </div>
                </section>

                <section>
                    <h2>✅ What AbstractCore Does Exceptionally Well</h2>
                    
                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">1. Universal LLM Provider Interface</h3>
                        <p><strong>What it does</strong>: Provides identical APIs across all major LLM providers.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># Same code works with any provider
def ask_llm(provider_name, question):
    llm = create_llm(provider_name, model="default")
    return llm.generate(question)

# All of these work identically
ask_llm("openai", "What is Python?")
ask_llm("anthropic", "What is Python?")
ask_llm("ollama", "What is Python?")</code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: No other library provides truly universal tool calling, streaming, and structured output across all providers.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">2. Production-Grade Reliability</h3>
                        <p><strong>What it does</strong>: Handles failures gracefully with retry logic, circuit breakers, and comprehensive error handling.</p>
                        
                        <ul>
                            <li><strong>Automatic retries</strong> with exponential backoff for rate limits and network errors</li>
                            <li><strong>Circuit breakers</strong> prevent cascade failures when providers go down</li>
                            <li><strong>Smart error classification</strong> - retries recoverable errors, fails fast on auth errors</li>
                            <li><strong>Event system</strong> for monitoring and alerting</li>
                        </ul>
                        
                        <p><strong>Why it's exceptional</strong>: Built for production from day one, not research or prototypes.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">3. Universal Tool Calling</h3>
                        <p><strong>What it does</strong>: Tools work consistently across ALL providers, even those without native tool support.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python">from abstractcore import create_llm, tool

@tool
def get_weather(city: str) -> str:
    """Get weather for a city."""
    return f"Weather in {city}: 72°F, sunny"

# Works with providers that have native tool support
openai_response = openai_llm.generate("Weather in Paris?", tools=[get_weather])

# Also works with providers that don't (via intelligent prompting)
ollama_response = ollama_llm.generate("Weather in Paris?", tools=[get_weather])</code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: Most libraries only support OpenAI-style tools. AbstractCore makes ANY model work with tools.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">4. Centralized Configuration System</h3>
                        <p><strong>What it does</strong>: Single source of truth for all settings with clear priority hierarchy.</p>

                        <div class="code-block">
                            <pre><code class="language-bash"># One-time configuration
abstractcore --status
abstractcore --set-global-default ollama/llama3:8b
abstractcore --set-app-default summarizer openai gpt-4o-mini
abstractcore --set-api-key openai sk-your-key-here
abstractcore --download-vision-model

# Now use anywhere without repeating config
summarizer document.pdf  # Uses configured defaults
python -m abstractcore.utils.cli --prompt "Hello"  # Uses CLI default</code></pre>
                        </div>

                        <p><strong>Why it's exceptional</strong>: Configuration priority (Explicit > App-Specific > Global > Hardcoded) eliminates repetitive parameter passing while maintaining full control when needed.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">5. Universal Media Handling System</h3>
                        <p><strong>What it does</strong>: Attach any file type (images, PDFs, Office docs, data) with simple <code>@filename</code> syntax or <code>media=[]</code> parameter.</p>

                        <div class="code-block">
                            <pre><code class="language-python"># Python API - works across ALL providers
llm = create_llm("openai", model="gpt-4o")
response = llm.generate(
    "Compare the chart with the data and summarize the document",
    media=["chart.png", "data.csv", "report.pdf"]
)

# CLI - same simplicity
# python -m abstractcore.utils.cli --prompt "Analyze @report.pdf and @chart.png"

# Supported: Images (PNG, JPEG, GIF, WEBP, BMP, TIFF)
#            Documents (PDF, DOCX, XLSX, PPTX)
#            Data (CSV, TSV, TXT, MD, JSON)</code></pre>
                        </div>

                        <p><strong>Why it's exceptional</strong>: Same code works identically across OpenAI, Anthropic, Ollama, and all providers. Automatic processor selection, provider-specific formatting, and graceful fallback.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">6. Vision Capabilities with Intelligent Fallback</h3>
                        <p><strong>What it does</strong>: Image analysis across all providers with automatic resolution optimization. Text-only models can process images through transparent vision fallback.</p>

                        <div class="code-block">
                            <pre><code class="language-python"># Works with vision-capable models
llm = create_llm("openai", model="gpt-4o")
response = llm.generate(
    "What's in this image?",
    media=["photo.jpg"]
)

# Also works with text-only models via vision fallback
text_llm = create_llm("lmstudio", model="qwen/qwen3-next-80b")  # No native vision
response = text_llm.generate(
    "Analyze this image",
    media=["complex_scene.jpg"]
)
# Transparent: vision model analyzes → text model processes description</code></pre>
                        </div>

                        <p><strong>Why it's exceptional</strong>: Automatic image optimization per model, cross-provider consistency, and unique vision fallback system enables ANY model to process images.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">7. Tool Call Tag Rewriting for Agentic CLI Compatibility</h3>
                        <p><strong>What it does</strong>: Automatically rewrites tool call tags to match different agentic CLI requirements in real-time.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># Rewrite tool calls for different CLIs
llm = create_llm("openai", model="gpt-4o-mini")

# For Codex CLI (Qwen3 format)
response = llm.generate("Weather in Paris?", tools=tools, tool_call_tags="qwen3")
# Output: <|tool_call|>{"name": "get_weather", "arguments": {"location": "Paris"}}</|tool_call|>

# For Crush CLI (LLaMA3 format)  
response = llm.generate("Weather in Paris?", tools=tools, tool_call_tags="llama3")
# Output: <function_call>{"name": "get_weather", "arguments": {"location": "Paris"}}</function_call>

# For Gemini CLI (XML format)
response = llm.generate("Weather in Paris?", tools=tools, tool_call_tags="xml")
# Output: <tool_call>{"name": "get_weather", "arguments": {"location": "Paris"}}</tool_call></code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: Seamless compatibility with any agentic CLI without code changes.</p>
                    </div>

                    <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: var(--secondary-color);">8. Structured Output with Automatic Retry</h3>
                        <p><strong>What it does</strong>: Gets typed Python objects from LLMs with automatic validation and retry on failures.</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python">from pydantic import BaseModel

class Product(BaseModel):
    name: str
    price: float

# Automatically retries with error feedback if validation fails
product = llm.generate(
    "Extract: Gaming laptop for $1200",
    response_model=Product
)</code></pre>
                        </div>
                        
                        <p><strong>Why it's exceptional</strong>: Built-in validation retry means higher success rates and less manual error handling.</p>
                    </div>
                </section>

                <section>
                    <h2>❌ What AbstractCore Does NOT Do</h2>
                    <p style="color: var(--text-secondary); margin-bottom: 2rem;">Understanding limitations is crucial for choosing the right tool.</p>
                    
                    <div style="background: #fef2f2; border-left: 4px solid #dc2626; padding: 2rem; border-radius: 0.5rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: #991b1b;">1. RAG Pipelines (Use Specialized Tools)</h3>
                        <p style="color: #1f2937;"><strong>What AbstractCore provides</strong>: Vector embeddings via <code>EmbeddingManager</code></p>
                        <p style="color: #1f2937;"><strong>What it doesn't provide</strong>: Document chunking, vector databases, retrieval strategies</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># AbstractCore gives you this
from abstractcore.embeddings import EmbeddingManager
embedder = EmbeddingManager()
similarity = embedder.compute_similarity("query", "document")

# You need to build this yourself
def rag_pipeline(query, documents):
    # 1. Chunk documents - YOU implement
    # 2. Store in vector DB - YOU implement
    # 3. Retrieve relevant chunks - YOU implement
    # 4. Construct prompt - YOU implement
    return llm.generate(prompt)</code></pre>
                        </div>

                        <p style="color: #1f2937;"><strong>Better alternatives</strong>:</p>
                        <ul style="color: #1f2937;">
                            <li><strong><a href="https://github.com/run-llama/llama_index" target="_blank" style="color: #2563eb;">LlamaIndex</a></strong> - Full RAG framework</li>
                            <li><strong><a href="https://github.com/langchain-ai/langchain" target="_blank" style="color: #2563eb;">LangChain</a></strong> - RAG components and chains</li>
                        </ul>
                    </div>

                    <div style="background: #fef2f2; border-left: 4px solid #dc2626; padding: 2rem; border-radius: 0.5rem; margin: 2rem 0;">
                        <h3 style="margin: 0 0 1rem 0; color: #991b1b;">2. Complex Agent Workflows (Use Agent Frameworks)</h3>
                        <p style="color: #1f2937;"><strong>What AbstractCore provides</strong>: Single LLM calls with tool execution</p>
                        <p style="color: #1f2937;"><strong>What it doesn't provide</strong>: Multi-step agent reasoning, planning, memory persistence</p>
                        
                        <div class="code-block">
                            <pre><code class="language-python"># AbstractCore is great for this
response = llm.generate("What's 2+2?", tools=[calculator_tool])

# AbstractCore is NOT for this
def complex_agent():
    # 1. Plan multi-step solution - NOT provided
    # 2. Execute steps with memory - NOT provided
    # 3. Reflect and re-plan - NOT provided
    # 4. Persist agent state - NOT provided
    pass</code></pre>
                        </div>

                        <p style="color: #1f2937;"><strong>Better alternatives</strong>:</p>
                        <ul style="color: #1f2937;">
                            <li><strong><a href="https://github.com/lpalbou/AbstractAgent" target="_blank" style="color: #2563eb;">AbstractAgent</a></strong> - Built on AbstractCore</li>
                            <li><strong><a href="https://github.com/langchain-ai/langgraph" target="_blank" style="color: #2563eb;">LangGraph</a></strong> - Agent orchestration</li>
                            <li><strong><a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" style="color: #2563eb;">AutoGPT</a></strong> - Autonomous agents</li>
                        </ul>
                    </div>
                </section>

                <section>
                    <h2>When to Choose AbstractCore</h2>
                    
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem; margin: 2rem 0;">
                        <div>
                            <h3 style="color: var(--secondary-color);">✅ Choose AbstractCore When You Need:</h3>
                            <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem;">
                                <ol>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Reliable LLM Infrastructure</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Production-ready error handling and retry logic</li>
                                            <li>Consistent interface across different providers</li>
                                            <li>Built-in monitoring and observability</li>
                                        </ul>
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Provider Flexibility</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Easy switching between OpenAI, Anthropic, Ollama, etc.</li>
                                            <li>Provider-agnostic code that runs anywhere</li>
                                            <li>Local and cloud provider support</li>
                                        </ul>
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Universal Tool Calling</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Tools that work across ALL providers</li>
                                            <li>Consistent tool execution regardless of native support</li>
                                            <li>Event-driven tool control and monitoring</li>
                                        </ul>
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Centralized Configuration</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Single source of truth for all settings</li>
                                            <li>Clear priority hierarchy (Explicit > App > Global > Default)</li>
                                            <li>No repetitive parameter passing</li>
                                        </ul>
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Universal Media Handling</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Attach images, PDFs, Office docs, data files</li>
                                            <li>Same API across all providers</li>
                                            <li>Automatic processing and formatting</li>
                                        </ul>
                                    </li>
                                    <li>
                                        <strong>Vision Capabilities</strong>
                                        <ul style="margin-top: 0.5rem;">
                                            <li>Image analysis across all providers</li>
                                            <li>Automatic resolution optimization</li>
                                            <li>Vision fallback for text-only models</li>
                                        </ul>
                                    </li>
                                </ol>
                            </div>
                        </div>
                        
                        <div>
                            <h3 style="color: #991b1b;">❌ Don't Choose AbstractCore When You Need:</h3>
                            <div style="background: #fef2f2; border-left: 4px solid #dc2626; padding: 1.5rem; border-radius: 0.5rem;">
                                <ol style="color: #1f2937;">
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Full RAG Frameworks</strong> → Use LlamaIndex or LangChain
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Complex Agent Workflows</strong> → Use AbstractAgent or LangGraph
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Advanced Memory Systems</strong> → Use AbstractMemory or Mem0
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Prompt Template Management</strong> → Use Jinja2 or LangChain Prompts
                                    </li>
                                    <li style="margin-bottom: 1rem;">
                                        <strong>Model Training/Fine-tuning</strong> → Use Transformers or Axolotl
                                    </li>
                                    <li>
                                        <strong>Multi-Agent Systems</strong> → Use CrewAI or AutoGen
                                    </li>
                                </ol>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Related Documentation -->
                <div style="margin-top: 4rem; padding: 2rem; background: var(--background-secondary); border-radius: 0.75rem;">
                    <h2 style="margin: 0 0 1.5rem 0;">Related Documentation</h2>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem;">
                        <a href="getting-started.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Getting Started</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">5-minute quick start guide</p>
                        </a>

                        <a href="centralized-config.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Centralized Configuration</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Global settings and defaults</p>
                        </a>

                        <a href="media-handling-system.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Media Handling</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Universal file attachment</p>
                        </a>

                        <a href="vision-capabilities.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Vision Capabilities</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Image analysis with fallback</p>
                        </a>

                        <a href="api-reference.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">API Reference</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Complete Python API documentation</p>
                        </a>

                        <a href="tool-calling.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Tool Calling</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Universal tool system guide</p>
                        </a>

                        <a href="examples.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                            <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Examples</h4>
                            <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Real-world usage examples</p>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
