# JavaScript Rendering for `fetch_url`

## Overview

The `fetch_url` tool from `abstractcore.tools.common_tools` now supports optional JavaScript rendering for dynamic websites. This enhancement allows you to retrieve fully rendered content from JavaScript-heavy sites that don't work with traditional HTTP requests.

## When to Use JavaScript Rendering

### Use `render_js=True` for:
- **Single Page Applications (SPAs)**: React, Vue, Angular apps
- **Dynamic content sites**: Google Scholar, LinkedIn, Twitter/X
- **AJAX-loaded content**: Sites that load data after the initial page load
- **Client-side rendered sites**: Content generated by JavaScript

### Use `render_js=False` (default) for:
- **Static HTML pages**: Traditional websites
- **Server-side rendered sites**: Most blogs, documentation sites
- **APIs**: JSON/XML endpoints
- **Performance-critical tasks**: When speed matters more than dynamic content

## Installation

JavaScript rendering requires additional dependencies:

```bash
pip install requests-html lxml_html_clean
```

**Note**: On first use, the library will automatically download Chromium (~141MB) to your home directory. This is a one-time download.

## Usage Examples

### Basic Example

```python
from abstractcore.tools.common_tools import fetch_url

# Static content (fast, default)
result = fetch_url("https://example.com")

# JavaScript-rendered content (slower, more complete)
result_js = fetch_url(
    "https://scholar.google.com/citations?user=USERID",
    render_js=True
)
```

### Advanced Configuration

```python
# Custom JavaScript rendering settings
result = fetch_url(
    url="https://dynamic-site.com",
    render_js=True,
    js_timeout=30,      # Wait up to 30 seconds for rendering
    js_sleep=3,         # Wait 3 seconds after page load
    extract_links=True  # Extract all links (default)
)
```

### Error Handling

```python
# The function provides helpful error messages if dependencies are missing
result = fetch_url("https://example.com", render_js=True)

# If requests-html is not installed, you'll see:
# ‚ùå JavaScript rendering requires the 'requests-html' library
# Install it with: pip install requests-html lxml_html_clean
# Note: First use will download Chromium (~141MB)
```

## Performance Comparison

### Google Scholar Example

| Metric | Static (`render_js=False`) | JavaScript (`render_js=True`) |
|--------|---------------------------|------------------------------|
| **Execution Time** | <1 second | ~5-10 seconds |
| **Text Content** | 5,218 characters | 118,663 characters (22x more!) |
| **Publications Found** | 0 | 20 |
| **Real Links** | 0 | 9 |
| **Citation Data** | None | Yes ("Cited by 10,262") |
| **javascript:void(0) Links** | Many | 0 |

## Parameters

### Core Parameters
- **`url`** (str): The URL to fetch
- **`method`** (str): HTTP method - "GET" or "POST" (default: "GET")
- **`headers`** (dict): Optional custom headers
- **`timeout`** (int): Request timeout in seconds (default: 30)

### JavaScript Rendering Parameters
- **`render_js`** (bool): Enable JavaScript rendering (default: False)
- **`js_timeout`** (int): Maximum time for JavaScript rendering (default: 20 seconds)
- **`js_sleep`** (int): Wait time after page load for async content (default: 2 seconds)

### Content Processing Parameters
- **`extract_links`** (bool): Extract hyperlinks from HTML (default: True)
- **`include_binary_preview`** (bool): Include base64 preview for binary content (default: False)
- **`max_content_length`** (int): Maximum bytes to download (default: 10MB)

## Implementation Details

### Technology Stack
- **requests-html**: Lightweight wrapper around requests + pyppeteer
- **Chromium**: Headless browser for JavaScript execution (auto-downloaded)
- **BeautifulSoup**: HTML parsing and extraction

### Architecture
1. **URL Validation**: Checks URL format and scheme
2. **Rendering Decision**: Routes to JS or static fetch based on `render_js`
3. **JavaScript Execution**: Uses Chromium to render dynamic content
4. **Content Parsing**: Extracts title, description, headings, links, and text
5. **Result Formatting**: Returns structured, human-readable output

## Best Practices

### 1. Use Static Fetching by Default
```python
# Good: Fast and efficient for most sites
result = fetch_url("https://docs.python.org")

# Unnecessary: Python docs are static
result = fetch_url("https://docs.python.org", render_js=True)
```

### 2. Increase Timeouts for Slow Sites
```python
# Sites with heavy JavaScript may need more time
result = fetch_url(
    "https://heavy-app.com",
    render_js=True,
    js_timeout=30,  # Increased from default 20
    js_sleep=5      # Wait longer for async content
)
```

### 3. Handle Missing Dependencies Gracefully
```python
# Check if JavaScript rendering is available
from abstractcore.tools.common_tools import REQUESTS_HTML_AVAILABLE

if REQUESTS_HTML_AVAILABLE:
    result = fetch_url(url, render_js=True)
else:
    print("Install requests-html for JavaScript rendering")
    result = fetch_url(url, render_js=False)
```

## Troubleshooting

### Issue: "JavaScript rendering requires the 'requests-html' library"
**Solution**: Install dependencies
```bash
pip install requests-html lxml_html_clean
```

### Issue: Chromium download fails
**Solution**: Check disk space (~141MB required) and network connectivity. The download happens automatically on first use.

### Issue: Content not fully loaded
**Solution**: Increase `js_sleep` to allow more time for async content
```python
result = fetch_url(url, render_js=True, js_sleep=5)
```

### Issue: Timeout errors
**Solution**: Increase `js_timeout` for slow sites
```python
result = fetch_url(url, render_js=True, js_timeout=60)
```

## Comparison with Alternatives

| Feature | `fetch_url` (requests-html) | Selenium | Playwright | requests + BeautifulSoup |
|---------|----------------------------|----------|------------|--------------------------|
| **Setup Complexity** | Low (pip install) | Medium | Medium | Low |
| **Speed** | Medium | Slow | Fast | Very Fast |
| **JavaScript Support** | Yes | Yes | Yes | No |
| **Download Size** | ~141MB (Chromium) | ~150MB | ~200MB | ~5MB |
| **Multi-browser** | Chromium only | All browsers | All browsers | N/A |
| **Best For** | Quick JS rendering | Complex automation | Modern automation | Static sites only |

## Real-World Examples

### Example 1: Google Scholar Citations
```python
from abstractcore.tools.common_tools import fetch_url

url = "https://scholar.google.com/citations?user=29P1njkAAAAJ&hl=en"

# Static fetch - gets HTML but no publications
result_static = fetch_url(url, render_js=False)
# Returns: ~5,000 characters, no publication data

# JavaScript fetch - gets full content
result_js = fetch_url(url, render_js=True)
# Returns: ~118,000 characters, 20 publications, citation counts
```

### Example 2: Dynamic Search Results
```python
# Site that loads results via AJAX
result = fetch_url(
    "https://dynamic-search.com/results?q=python",
    render_js=True,
    js_sleep=3  # Wait for search results to load
)
```

### Example 3: SPA Navigation
```python
# Single Page Application with client-side routing
result = fetch_url(
    "https://react-app.com/#/profile/123",
    render_js=True,
    js_timeout=25
)
```

## Contributing

Found a bug or have a suggestion? Please report it in the project's issue tracker.

## Related Documentation

- [Common Tools API Reference](./common_tools.md)
- [Web Search Tools](./web_search.md)
- [File Tools](./file_tools.md)
