<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Examples - AbstractCore</title>
    <meta name="description" content="Real-world examples and use cases for AbstractCore. Learn from practical implementations.">
    <link rel="icon" type="image/x-icon" href="../assets/favicon.ico">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/css/main.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    
    <!-- Navbar Component -->
    <script src="../assets/js/navbar-component.js"></script>
</head>
<body>
    <!-- Navigation -->
    <div class="navbar-placeholder"></div>
    
    <script>
        // Initialize navbar with docs-specific configuration
        document.addEventListener('DOMContentLoaded', function() {
            createNavbar({
                basePath: '../',
                menuItems: [
                    { 
                        text: 'GitHub', 
                        href: 'https://github.com/lpalbou/AbstractCore',
                        target: '_blank',
                        icon: 'github'
                    },
                    { 
                        text: 'PyPI', 
                        href: 'https://pypi.org/project/abstractcore/',
                        target: '_blank',
                        icon: 'pypi'
                    }
                ]
            });
        });
    </script>

    <!-- Main Content -->
    <main style="padding-top: 5rem;">
        <div class="container" style="max-width: 1300px;">
            <div class="doc-header" style="margin-bottom: 3rem; text-align: center;">
                <h1 style="font-size: 2.5rem; margin-bottom: 1rem;">Real-World Examples</h1>
                <p style="font-size: 1.25rem; color: var(--text-secondary);">
                    Learn from practical examples and use cases. All examples work across any provider.
                </p>
            </div>

            <div class="examples-grid" style="display: grid; grid-template-columns: repeat(auto-fit, minmax(450px, 1fr)); gap: 2rem;">
                
                <!-- Provider Flexibility Example -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Provider Flexibility</h3>
                        <span class="example-badge">Core Feature</span>
                    </div>
                    <p class="example-description">
                        Switch between providers with identical code. Perfect for development vs production environments.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python"># Development (free, local)
llm_dev = create_llm("ollama", model="qwen3:4b")

# Production (high quality, cloud)
llm_prod = create_llm("openai", model="gpt-4o-mini")

# Same interface, different capabilities
def ask_question(llm, question):
    return llm.generate(question)

# Works with any provider
dev_answer = ask_question(llm_dev, "What is Python?")
prod_answer = ask_question(llm_prod, "What is Python?")</code></pre>
                    </div>
                </div>

                <!-- RAG Example -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">RAG with Embeddings</h3>
                        <span class="example-badge">Advanced</span>
                    </div>
                    <p class="example-description">
                        Build retrieval-augmented generation systems with built-in embedding support.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore.embeddings import EmbeddingManager
from abstractcore import create_llm

# Initialize components
embedder = EmbeddingManager()
llm = create_llm("openai", model="gpt-4o-mini")

# Documents to search
documents = [
    "Python is great for data science and machine learning.",
    "JavaScript powers modern web applications.",
    "Rust ensures memory safety without garbage collection."
]

# Create embeddings
doc_embeddings = embedder.embed_batch(documents)

# User query
query = "Tell me about web development"
query_embedding = embedder.embed(query)

# Find most similar document
similarities = [
    embedder.compute_similarity(query_embedding, doc_emb)
    for doc_emb in doc_embeddings
]

best_doc_idx = similarities.index(max(similarities))
context = documents[best_doc_idx]

# Generate response with context
response = llm.generate(
    f"Context: {context}\n\nQuestion: {query}\n\nAnswer:"
)
print(response.content)</code></pre>
                    </div>
                </div>

                <!-- Tool Calling Example -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Advanced Tool Calling</h3>
                        <span class="example-badge">Tools</span>
                    </div>
                    <p class="example-description">
                        Create sophisticated tool-enabled applications that work across all providers.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore import create_llm, tool
import requests
import json

@tool
def search_web(query: str) -> str:
    """Search the web for information."""
    # Simplified example - use actual search API
    return f"Search results for '{query}': [relevant information]"

@tool
def save_to_file(filename: str, content: str) -> str:
    """Save content to a file."""
    with open(filename, 'w') as f:
        f.write(content)
    return f"Saved content to {filename}"

@tool
def get_weather(city: str) -> str:
    """Get current weather for a city."""
    # Simplified example - use actual weather API
    return f"Weather in {city}: 72°F, sunny"

# Create LLM with tools
llm = create_llm("anthropic", model="claude-3-5-haiku-latest")

# Complex multi-tool request
response = llm.generate(
    """
    I need you to:
    1. Search for information about Python web frameworks
    2. Get the weather in San Francisco
    3. Save a summary to a file called 'research.txt'
    
    Please complete these tasks in order.
    """,
    tools=[search_web, get_weather, save_to_file]
)

print(response.content)</code></pre>
                    </div>
                </div>

                <!-- Structured Output Example -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Complex Structured Output</h3>
                        <span class="example-badge">Type Safe</span>
                    </div>
                    <p class="example-description">
                        Extract complex structured data with automatic validation and retry.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from pydantic import BaseModel, Field
from typing import List, Optional
from abstractcore import create_llm

class Address(BaseModel):
    street: str
    city: str
    state: str
    zip_code: str

class Person(BaseModel):
    name: str
    age: int = Field(gt=0, le=150)
    email: Optional[str] = None
    address: Address
    skills: List[str]

class Company(BaseModel):
    name: str
    employees: List[Person]
    founded_year: int
    headquarters: Address

llm = create_llm("openai", model="gpt-4o-mini")

# Extract complex nested data
company_data = """
TechCorp was founded in 2010 and is headquartered at 
123 Tech Street, San Francisco, CA 94105. 

Employees:
- John Doe, 30, john@techcorp.com, lives at 456 Oak Ave, 
  Palo Alto, CA 94301. Skills: Python, JavaScript, React.
- Jane Smith, 28, jane@techcorp.com, lives at 789 Pine St, 
  Mountain View, CA 94041. Skills: Go, Kubernetes, Docker.
"""

company = llm.generate(
    f"Extract company information: {company_data}",
    response_model=Company
)

print(f"Company: {company.name}")
print(f"Founded: {company.founded_year}")
print(f"Employees: {len(company.employees)}")
for emp in company.employees:
    print(f"  - {emp.name}, {emp.age}, {emp.address.city}")
    print(f"    Skills: {', '.join(emp.skills)}")</code></pre>
                    </div>
                </div>

                <!-- Streaming Example -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Real-Time Streaming</h3>
                        <span class="example-badge">Streaming</span>
                    </div>
                    <p class="example-description">
                        Build interactive applications with real-time streaming responses.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore import create_llm, tool
import time

@tool
def get_system_time() -> str:
    """Get the current system time."""
    return time.strftime("%Y-%m-%d %H:%M:%S")

def interactive_chat():
    llm = create_llm("openai", model="gpt-4o-mini")
    
    print("🤖 AI Assistant (type 'quit' to exit)")
    print("=" * 40)
    
    while True:
        user_input = input("\n👤 You: ")
        if user_input.lower() == 'quit':
            break
            
        print("🤖 AI: ", end="", flush=True)
        
        # Stream response with tool support
        for chunk in llm.generate(
            user_input,
            tools=[get_system_time],
            stream=True
        ):
            print(chunk.content, end="", flush=True)
            
            # Handle tool calls during streaming
            if chunk.tool_calls:
                print("\n🛠️  [Tool executed]", flush=True)
                print("🤖 AI: ", end="", flush=True)
        
        print()  # New line after response

# Run the interactive chat
if __name__ == "__main__":
    interactive_chat()</code></pre>
                    </div>
                </div>

                <!-- Media Handling - Image Analysis -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Image Analysis</h3>
                        <span class="example-badge">Media</span>
                    </div>
                    <p class="example-description">
                        Analyze images across all providers with automatic optimization and vision fallback.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore import create_llm

# Works with any vision-capable provider
llm = create_llm("openai", model="gpt-4o")

# Single image analysis
response = llm.generate(
    "What objects do you see in this image? Describe the scene.",
    media=["photo.jpg"]
)
print(response.content)

# Multiple images comparison
response = llm.generate(
    "Compare these three images and identify common themes",
    media=["image1.jpg", "image2.jpg", "image3.jpg"]
)
print(response.content)

# Works with vision fallback for text-only models
text_llm = create_llm("lmstudio", model="qwen/qwen3-next-80b")
response = text_llm.generate(
    "Analyze this image",
    media=["complex_scene.jpg"]
)
# Vision model analyzes → text model processes description
print(response.content)</code></pre>
                    </div>
                </div>

                <!-- Media Handling - Document Processing -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Document Processing</h3>
                        <span class="example-badge">Media</span>
                    </div>
                    <p class="example-description">
                        Process PDFs, Office documents, and data files with the same simple API.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore import create_llm

llm = create_llm("anthropic", model="claude-3.5-sonnet")

# PDF analysis
response = llm.generate(
    "Summarize the key findings in this report",
    media=["annual_report.pdf"]
)
print(response.content)

# Office documents
response = llm.generate(
    "Extract action items from this presentation",
    media=["meeting_slides.pptx"]
)
print(response.content)

# Excel data analysis
response = llm.generate(
    "What trends do you see in this sales data?",
    media=["sales_data.xlsx"]
)
print(response.content)

# CSV analysis
response = llm.generate(
    "Calculate the average and identify outliers",
    media=["metrics.csv"]
)
print(response.content)</code></pre>
                    </div>
                </div>

                <!-- Media Handling - Mixed Media -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Multi-Media Analysis</h3>
                        <span class="example-badge">Media</span>
                    </div>
                    <p class="example-description">
                        Combine images, documents, and data files in a single analysis request.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore import create_llm

llm = create_llm("openai", model="gpt-4o")

# Mixed media: chart + spreadsheet + report
response = llm.generate(
    """
    Compare the chart visualization with the raw data
    in the spreadsheet and verify it matches the
    findings in the PDF report. Identify any discrepancies.
    """,
    media=["quarterly_chart.png", "data.xlsx", "report.pdf"]
)
print(response.content)

# Real-world use case: Product analysis
response = llm.generate(
    """
    Analyze this product launch:
    - Review the design mockups
    - Check the market data
    - Summarize the strategy document

    Provide recommendations for launch timing.
    """,
    media=[
        "product_mockup_1.jpg",
        "product_mockup_2.jpg",
        "market_research.csv",
        "launch_strategy.docx"
    ]
)
print(response.content)</code></pre>
                    </div>
                </div>

                <!-- Session Management Example -->
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Session Management</h3>
                        <span class="example-badge">Memory</span>
                    </div>
                    <p class="example-description">
                        Build applications with persistent conversation memory and analytics.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore import create_llm, BasicSession
import json

def create_tutoring_session():
    llm = create_llm("anthropic", model="claude-3-5-haiku-latest")
    
    # Create session with system prompt
    session = BasicSession(
        provider=llm,
        system_prompt="""
        You are a helpful Python programming tutor. 
        Remember the student's progress and adapt your 
        teaching style to their level.
        """
    )
    
    # Simulate a tutoring conversation
    topics = [
        "I'm new to Python. Can you explain variables?",
        "How do I create a list?",
        "What's the difference between a list and a tuple?",
        "Can you give me a practice exercise?",
        "I'm confused about the exercise. Can you help?"
    ]
    
    for i, topic in enumerate(topics, 1):
        print(f"\n--- Session {i} ---")
        print(f"Student: {topic}")
        
        response = session.generate(topic)
        print(f"Tutor: {response.content[:100]}...")
        
        # Add metadata to track progress
        session.add_message(
            'user', 
            topic, 
            lesson_number=i,
            topic_category="python_basics"
        )
    
    # Save session with analytics
    session.save(
        'tutoring_session.json',
        summary=True,      # Generate conversation summary
        assessment=True,   # Assess learning progress
        facts=True        # Extract key facts learned
    )
    
    print("\n📊 Session saved with analytics!")
    
    # Load and continue session later
    loaded_session = BasicSession.load(
        'tutoring_session.json', 
        provider=llm
    )
    
    # Continue conversation
    followup = loaded_session.generate(
        "Can you summarize what we've covered so far?"
    )
    print(f"\nSummary: {followup.content}")

if __name__ == "__main__":
    create_tutoring_session()</code></pre>
                    </div>
                </div>

            </div>

            <!-- CLI Media Handling Section -->
            <div style="margin-top: 4rem;">
                <h2 style="text-align: center; margin-bottom: 1rem;">CLI Media Handling</h2>
                <p style="text-align: center; color: var(--text-secondary); margin-bottom: 2rem;">
                    Use the simple @filename syntax in CLI for instant file attachment
                </p>

                <div style="background: var(--background-secondary); padding: 2rem; border-radius: 0.75rem; max-width: 900px; margin: 0 auto;">
                    <div class="code-block">
                        <pre><code class="language-bash"># Image analysis
python -m abstractcore.utils.cli --prompt "What's in @photo.jpg"

# PDF document
python -m abstractcore.utils.cli --prompt "Summarize @report.pdf"

# Office documents
python -m abstractcore.utils.cli --prompt "Extract key points from @slides.pptx"
python -m abstractcore.utils.cli --prompt "What data is in @spreadsheet.xlsx"

# Data files
python -m abstractcore.utils.cli --prompt "Analyze trends in @sales_data.csv"

# Multiple files
python -m abstractcore.utils.cli --prompt "Compare @chart.png and @data.csv"

# Mixed media analysis
python -m abstractcore.utils.cli --prompt "Verify @chart.png matches @data.xlsx and @report.pdf"</code></pre>
                    </div>
                </div>
            </div>

            <!-- More Examples Section -->
            <div style="margin-top: 4rem; text-align: center;">
                <h2>More Examples</h2>
                <p style="color: var(--text-secondary); margin-bottom: 2rem;">
                    Find more examples in the GitHub repository
                </p>
                
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem; margin: 2rem 0;">
                    <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; border: 1px solid var(--border-light);">
                        <h4 style="margin: 0 0 0.5rem 0;">🚀 Progressive Examples</h4>
                        <p style="margin: 0 0 1rem 0; color: var(--text-secondary); font-size: 0.875rem;">Step-by-step learning path</p>
                        <a href="https://github.com/lpalbou/AbstractCore/tree/main/examples/progressive" target="_blank" style="color: var(--primary-color); font-weight: 500;">View on GitHub →</a>
                    </div>
                    
                    <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; border: 1px solid var(--border-light);">
                        <h4 style="margin: 0 0 0.5rem 0;">🏭 Production Examples</h4>
                        <p style="margin: 0 0 1rem 0; color: var(--text-secondary); font-size: 0.875rem;">Enterprise deployment patterns</p>
                        <a href="https://github.com/lpalbou/AbstractCore/tree/main/examples/example_06_production" target="_blank" style="color: var(--primary-color); font-weight: 500;">View on GitHub →</a>
                    </div>
                    
                    <div style="background: var(--background-secondary); padding: 1.5rem; border-radius: 0.75rem; border: 1px solid var(--border-light);">
                        <h4 style="margin: 0 0 0.5rem 0;">🔧 Complete RAG</h4>
                        <p style="margin: 0 0 1rem 0; color: var(--text-secondary); font-size: 0.875rem;">Full RAG implementation</p>
                        <a href="https://github.com/lpalbou/AbstractCore/blob/main/examples/complete_rag_example.py" target="_blank" style="color: var(--primary-color); font-weight: 500;">View on GitHub →</a>
                    </div>
                </div>
            </div>

            <!-- Related Documentation -->
            <div style="margin-top: 4rem; padding: 2rem; background: var(--background-secondary); border-radius: 0.75rem;">
                <h2 style="margin: 0 0 1.5rem 0; text-align: center;">Related Documentation</h2>
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem;">
                    <a href="getting-started.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                        <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Getting Started</h4>
                        <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Quick setup guide</p>
                    </a>

                    <a href="centralized-config.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                        <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Centralized Configuration</h4>
                        <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Global defaults and settings</p>
                    </a>

                    <a href="media-handling-system.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                        <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Media Handling</h4>
                        <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Universal file attachment system</p>
                    </a>

                    <a href="vision-capabilities.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                        <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Vision Capabilities</h4>
                        <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Image analysis with fallback</p>
                    </a>

                    <a href="tool-calling.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                        <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">Tool Calling</h4>
                        <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Universal tool system</p>
                    </a>

                    <a href="api-reference.html" style="display: block; padding: 1rem; background: var(--background); border-radius: 0.5rem; text-decoration: none; border: 1px solid var(--border-light); transition: all 0.15s ease;">
                        <h4 style="margin: 0 0 0.5rem 0; color: var(--primary-color);">API Reference</h4>
                        <p style="margin: 0; color: var(--text-secondary); font-size: 0.875rem;">Complete Python API</p>
                    </a>
                </div>
            </div>
        </div>
    </main>

    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
