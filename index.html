<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AbstractCore - Unified LLM Provider Interface</title>
    <meta name="description" content="A unified, powerful Python library for seamless interaction with multiple Large Language Model (LLM) providers. Write once, run everywhere.">
    <meta name="keywords" content="LLM, AI, Python, OpenAI, Anthropic, Ollama, Machine Learning, API">
    <meta name="author" content="AbstractCore Team">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://lpalbou.github.io/AbstractCore/">
    <meta property="og:title" content="AbstractCore - Unified LLM Provider Interface">
    <meta property="og:description" content="A unified, powerful Python library for seamless interaction with multiple Large Language Model (LLM) providers. Write once, run everywhere.">
    <meta property="og:image" content="https://lpalbou.github.io/AbstractCore/assets/og-image.png">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://lpalbou.github.io/AbstractCore/">
    <meta property="twitter:title" content="AbstractCore - Unified LLM Provider Interface">
    <meta property="twitter:description" content="A unified, powerful Python library for seamless interaction with multiple Large Language Model (LLM) providers. Write once, run everywhere.">
    <meta property="twitter:image" content="https://lpalbou.github.io/AbstractCore/assets/og-image.png">

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href="assets/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="assets/favicon-16x16.png">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    
    <!-- Styles -->
    <link rel="stylesheet" href="assets/css/main.css">
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    
    <!-- Navbar Component -->
    <script src="assets/js/navbar-component.js"></script>
    
    <!-- Analytics -->
    <script defer data-domain="lpalbou.github.io" src="https://plausible.io/js/script.js"></script>
    
    <!-- AI Documentation Styles -->
    <style>
        .hero-note {
            margin: 1.5rem 0;
            padding: 1rem 1.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            text-align: center;
        }
        .ai-docs-note {
            color: white;
            margin: 0;
            font-size: 0.95rem;
        }
        .ai-link {
            color: #ffd700;
            text-decoration: none;
            font-weight: 600;
            padding: 0.2rem 0.4rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
            transition: all 0.2s ease;
        }
        .ai-link:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-1px);
        }
        .section-description .ai-link {
            color: #667eea;
            background: rgba(102, 126, 234, 0.1);
        }
        .section-description .ai-link:hover {
            background: rgba(102, 126, 234, 0.2);
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <div class="navbar-placeholder"></div>

    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-container">
            <div class="hero-content">
                <h1 class="hero-title">
                    <span class="gradient-text">Unified LLM Interface</span>
                    <br>Write once, run everywhere
                </h1>
                <p class="hero-description">
                    A powerful Python library providing seamless interaction with all major LLM providers. 
                    Switch between OpenAI, Anthropic, Ollama, and more with identical code.
                </p>
                
                <div class="hero-actions">
                    <a href="#quickstart" class="btn btn-primary">
                        <svg class="btn-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                        </svg>
                        Quick Start
                    </a>
                    <a href="https://github.com/lpalbou/AbstractCore" class="btn btn-secondary" target="_blank">
                        <svg class="btn-icon" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                        </svg>
                        View on GitHub
                    </a>
                    <a href="https://pypi.org/project/abstractcore/" class="btn btn-secondary" target="_blank">
                        <svg class="btn-icon" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 0C5.373 0 0 5.373 0 12s5.373 12 12 12 12-5.373 12-12S18.627 0 12 0zm-1.5 6h3c.825 0 1.5.675 1.5 1.5v3c0 .825-.675 1.5-1.5 1.5H12v1.5h3V15H9V7.5c0-.825.675-1.5 1.5-1.5zm0 1.5v3h3v-3h-3z"/>
                        </svg>
                        View on PyPI
                    </a>
                </div>

                <div class="hero-note">
                    <p class="ai-docs-note">
                        🤖 <strong>For AI Agents:</strong> Use our AI-optimized documentation at 
                        <a href="https://www.abstractcore.ai/llms.txt" class="ai-link">llms.txt</a> (concise) or 
                        <a href="https://www.abstractcore.ai/llms-full.txt" class="ai-link">llms-full.txt</a> (complete) for seamless integration.
                    </p>
                </div>

                <div class="hero-stats">
                    <div class="stat">
                        <div class="stat-number">6+</div>
                        <div class="stat-label">Providers</div>
                    </div>
                    <div class="stat">
                        <div class="stat-number">137+</div>
                        <div class="stat-label">Models</div>
                    </div>
                    <div class="stat">
                        <div class="stat-number">MIT</div>
                        <div class="stat-label">License</div>
                    </div>
                </div>
            </div>
            
            <div class="hero-code">
                <div class="code-window">
                    <div class="code-header">
                        <div class="code-dots">
                            <span class="dot red"></span>
                            <span class="dot yellow"></span>
                            <span class="dot green"></span>
                        </div>
                        <div class="code-title">example.py</div>
                    </div>
                    <div class="code-content">
                        <pre><code class="language-python">from abstractcore import create_llm

# Works with any provider - just change the name
llm = create_llm("anthropic", model="claude-haiku-4.5")
response = llm.generate("What is the capital of France?")
print(response.content)

# Switch providers with zero code changes
llm = create_llm("openai", model="gpt-4o-mini")
llm = create_llm("ollama", model="qwen3-coder:30b")

# Same interface, same results ✨</code></pre>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Features Section -->
    <section id="features" class="features">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Why Choose AbstractCore?</h2>
                <p class="section-description">
                    Production-ready LLM infrastructure with everything you need to build reliable AI applications.
                </p>
            </div>
            
            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M12 2L2 7l10 5 10-5-10-5z"/>
                            <path d="M2 17l10 5 10-5"/>
                            <path d="M2 12l10 5 10-5"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Provider Discovery</h3>
                    <p class="feature-description">
                        Centralized registry with 137+ models across 6 providers. Programmatically discover all available providers and models with comprehensive metadata.
                    </p>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M9 12l2 2 4-4"/>
                            <path d="M21 12c-1 0-3-1-3-3s2-3 3-3 3 1 3 3-2 3-3 3"/>
                            <path d="M3 12c1 0 3-1 3-3s-2-3-3-3-3 1-3 3 2 3 3 3"/>
                            <path d="M3 12h6m6 0h6"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Production Ready</h3>
                    <p class="feature-description">
                        Built-in retry logic, circuit breakers, comprehensive error handling, and event-driven observability.
                    </p>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M14.7 6.3a1 1 0 0 0 0 1.4l1.6 1.6a1 1 0 0 0 1.4 0l3.77-3.77a6 6 0 0 1-7.94 7.94l-6.91 6.91a2.12 2.12 0 0 1-3-3l6.91-6.91a6 6 0 0 1 7.94-7.94l-3.76 3.76z"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Universal Tools + Syntax Rewriting</h3>
                    <p class="feature-description">
                        Tool calling across ALL providers with real-time format conversion for agent CLI compatibility. Architecture-aware detection and custom tag support.
                    </p>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2"/>
                            <rect x="8" y="2" width="8" height="4" rx="1" ry="1"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Type Safe</h3>
                    <p class="feature-description">
                        Full Pydantic integration for structured outputs with automatic validation and retry on failures.
                    </p>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M3 7v10a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2H5a2 2 0 0 0-2 2z"/>
                            <path d="M8 21v-4a2 2 0 0 1 2-2h4a2 2 0 0 1 2 2v4"/>
                            <path d="M9 7V4a2 2 0 0 1 2-2h2a2 2 0 0 1 2 2v3"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Local & Cloud</h3>
                    <p class="feature-description">
                        Run models locally for privacy and cost savings, or use cloud APIs for maximum performance.
                    </p>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M21 16V8a2 2 0 0 0-1-1.73l-7-4a2 2 0 0 0-2 0l-7 4A2 2 0 0 0 3 8v8a2 2 0 0 0 1 1.73l7 4a2 2 0 0 0 2 0l7-4A2 2 0 0 0 21 16z"/>
                            <polyline points="7.5,4.21 12,6.81 16.5,4.21"/>
                            <polyline points="7.5,19.79 7.5,14.6 3,12"/>
                            <polyline points="21,12 16.5,14.6 16.5,19.79"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Token Management + Streaming</h3>
                    <p class="feature-description">
                        Unified token parameters across all providers with budget validation. Real-time streaming with proper tool call handling and cost estimation.
                    </p>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <rect x="3" y="3" width="18" height="18" rx="2" ry="2"/>
                            <circle cx="9" cy="9" r="2"/>
                            <path d="M21 15l-3.086-3.086a2 2 0 0 0-2.828 0L6 21"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Session Management + Analytics</h3>
                    <p class="feature-description">
                        Persistent conversations with SOTA 2025 auto-compaction algorithm. Built-in analytics: summaries, assessments, fact extraction with complete serialization.
                    </p>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
                            <polyline points="14,2 14,8 20,8"/>
                            <line x1="16" y1="13" x2="8" y2="13"/>
                            <line x1="16" y1="17" x2="8" y2="17"/>
                            <polyline points="10,9 9,9 8,9"/>
                        </svg>
                    </div>
                    <h3 class="feature-title">Production Resilience + OpenAI Server</h3>
                    <p class="feature-description">
                        Production-grade retry logic, circuit breakers, and event-driven monitoring. OpenAI-compatible HTTP server for multi-language access.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Quick Start Section -->
    <section id="quickstart" class="quickstart">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Get Started in Minutes</h2>
                <p class="section-description">
                    Install AbstractCore and make your first LLM call in under 5 minutes.
                </p>
            </div>
            
            <div class="quickstart-content">
                <div class="quickstart-steps">
                    <div class="step">
                        <div class="step-number">1</div>
                        <div class="step-content">
                            <h3 class="step-title">Install</h3>
                            <p class="step-description">Install AbstractCore with your preferred providers</p>
                            <div class="code-block">
                                <pre><code class="language-bash"># Install everything
pip install abstractcore[all]

# Or install specific providers
pip install abstractcore[openai]
pip install abstractcore[anthropic]</code></pre>
                            </div>
                        </div>
                    </div>
                    
                    <div class="step">
                        <div class="step-number">2</div>
                        <div class="step-content">
                            <h3 class="step-title">Configure</h3>
                            <p class="step-description">Set up your API keys or local providers</p>
                            <div class="code-block">
                                <pre><code class="language-bash"># For cloud providers
export OPENAI_API_KEY="your-key-here"
export ANTHROPIC_API_KEY="your-key-here"

# For local providers (no keys needed)
# Install Ollama, LMStudio, or MLX</code></pre>
                            </div>
                        </div>
                    </div>
                    
                    <div class="step">
                        <div class="step-number">3</div>
                        <div class="step-content">
                            <h3 class="step-title">Code</h3>
                            <p class="step-description">Start building with the unified interface</p>
                            <div class="code-block">
                                <pre><code class="language-python">from abstractcore import create_llm

# Create LLM instance
llm = create_llm("openai", model="gpt-4o-mini")

# Generate response
response = llm.generate("Hello, world!")
print(response.content)</code></pre>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="quickstart-demo">
                    <div class="demo-tabs">
                        <button class="tab-button active" data-tab="basic">Provider Discovery</button>
                        <button class="tab-button" data-tab="tools">Tool Calling</button>
                        <button class="tab-button" data-tab="structured">Session Analytics</button>
                        <button class="tab-button" data-tab="streaming">Token Management</button>
                        <button class="tab-button" data-tab="cli">HTTP Server</button>
                    </div>
                    
                    <div class="demo-content">
                        <div class="demo-panel active" id="basic">
                            <div class="code-window">
                                <div class="code-header">
                                    <div class="code-dots">
                                        <span class="dot red"></span>
                                        <span class="dot yellow"></span>
                                        <span class="dot green"></span>
                                    </div>
                                    <div class="code-title">provider_discovery.py</div>
                                    <button class="copy-button" onclick="copyCode(this)" data-code="from abstractcore.providers import get_all_providers_with_models

# Get comprehensive information about all providers
providers = get_all_providers_with_models()
for provider in providers:
    print(f&quot;{provider['display_name']}: {provider['model_count']} models&quot;)
    print(f&quot;Features: {', '.join(provider['supported_features'])}&quot;)
    print(f&quot;Local: {provider['local_provider']}&quot;)
    print(f&quot;Auth Required: {provider['authentication_required']}&quot;)
    print()">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                            <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                            <path d="m5 15-4-4 4-4"></path>
                                            <path d="M5 5a2 2 0 0 0-2 2v6c0 1.1.9 2 2 2h2"></path>
                                        </svg>
                                        Copy
                                    </button>
                                </div>
                                <div class="code-content">
                                    <pre><code class="language-python">from abstractcore.providers import get_all_providers_with_models

# Get comprehensive information about all providers
providers = get_all_providers_with_models()
for provider in providers:
    print(f"{provider['display_name']}: {provider['model_count']} models")
    print(f"Features: {', '.join(provider['supported_features'])}")
    print(f"Local: {provider['local_provider']}")
    print(f"Auth Required: {provider['authentication_required']}")
    print()</code></pre>
                                </div>
                            </div>
                        </div>
                        
                        <div class="demo-panel" id="tools">
                            <div class="code-window">
                                <div class="code-header">
                                    <div class="code-dots">
                                        <span class="dot red"></span>
                                        <span class="dot yellow"></span>
                                        <span class="dot green"></span>
                                    </div>
                                    <div class="code-title">tool_syntax_rewriting.py</div>
                                    <button class="copy-button" onclick="copyCode(this)" data-code="from abstractcore import create_llm
from abstractcore.tools import tool

@tool
def calculate(expression: str) -&gt; float:
    &quot;&quot;&quot;Perform mathematical calculation.&quot;&quot;&quot;
    return eval(expression)

# Custom tag configuration for agent CLI compatibility
llm = create_llm(
    &quot;ollama&quot;,
    model=&quot;qwen3-coder:30b&quot;,
    tool_call_tags=&quot;function_call&quot;  # Converts to &lt;function_call&gt;...&lt;/function_call&gt;
)

# Real-time streaming with format conversion
for chunk in llm.generate(&quot;Calculate 15 * 23&quot;, tools=[calculate], stream=True):
    if chunk.tool_calls:
        print(f&quot;Tool detected: {chunk.tool_calls[0].name}&quot;)
    print(chunk.content, end=&quot;&quot;, flush=True)">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                            <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                            <path d="m5 15-4-4 4-4"></path>
                                            <path d="M5 5a2 2 0 0 0-2 2v6c0 1.1.9 2 2 2h2"></path>
                                        </svg>
                                        Copy
                                    </button>
                                </div>
                                <div class="code-content">
                                    <pre><code class="language-python">from abstractcore import create_llm
from abstractcore.tools import tool

@tool
def calculate(expression: str) -> float:
    """Perform mathematical calculation."""
    return eval(expression)

# Custom tag configuration for agent CLI compatibility
llm = create_llm(
    "ollama",
    model="qwen3-coder:30b",
    tool_call_tags="function_call"  # Converts to <function_call>...</function_call>
)

# Real-time streaming with format conversion
for chunk in llm.generate("Calculate 15 * 23", tools=[calculate], stream=True):
    if chunk.tool_calls:
        print(f"Tool detected: {chunk.tool_calls[0].name}")
    print(chunk.content, end="", flush=True)</code></pre>
                                </div>
                            </div>
                        </div>
                        
                        <div class="demo-panel" id="structured">
                            <div class="code-window">
                                <div class="code-header">
                                    <div class="code-dots">
                                        <span class="dot red"></span>
                                        <span class="dot yellow"></span>
                                        <span class="dot green"></span>
                                    </div>
                                    <div class="code-title">session_analytics.py</div>
                                    <button class="copy-button" onclick="copyCode(this)" data-code="from abstractcore import BasicSession, create_llm

llm = create_llm(&quot;openai&quot;, model=&quot;gpt-4o-mini&quot;)
session = BasicSession(llm, system_prompt=&quot;You are a helpful assistant.&quot;)

response1 = session.generate(&quot;My name is Alice&quot;)
response2 = session.generate(&quot;What's my name?&quot;)  # Remembers context

# Auto-compaction with SOTA 2025 algorithm
session.compact(target_tokens=8000)  # Compresses while preserving context

# Advanced analytics
summary = session.generate_summary(style=&quot;executive&quot;, length=&quot;brief&quot;)
assessment = session.generate_assessment(criteria=[&quot;clarity&quot;, &quot;helpfulness&quot;])
facts = session.extract_facts(entity_types=[&quot;person&quot;, &quot;organization&quot;, &quot;date&quot;])

# Save with analytics
session.save(&quot;conversation.json&quot;, summary=True, assessment=True, facts=True)">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                            <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                            <path d="m5 15-4-4 4-4"></path>
                                            <path d="M5 5a2 2 0 0 0-2 2v6c0 1.1.9 2 2 2h2"></path>
                                        </svg>
                                        Copy
                                    </button>
                                </div>
                                <div class="code-content">
                                    <pre><code class="language-python">from abstractcore import BasicSession, create_llm

llm = create_llm("openai", model="gpt-4o-mini")
session = BasicSession(llm, system_prompt="You are a helpful assistant.")

response1 = session.generate("My name is Alice")
response2 = session.generate("What's my name?")  # Remembers context

# Auto-compaction with SOTA 2025 algorithm
session.compact(target_tokens=8000)  # Compresses while preserving context

# Advanced analytics
summary = session.generate_summary(style="executive", length="brief")
assessment = session.generate_assessment(criteria=["clarity", "helpfulness"])
facts = session.extract_facts(entity_types=["person", "organization", "date"])

# Save with analytics
session.save("conversation.json", summary=True, assessment=True, facts=True)</code></pre>
                                </div>
                            </div>
                        </div>
                        
                        <div class="demo-panel" id="streaming">
                            <div class="code-window">
                                <div class="code-header">
                                    <div class="code-dots">
                                        <span class="dot red"></span>
                                        <span class="dot yellow"></span>
                                        <span class="dot green"></span>
                                    </div>
                                    <div class="code-title">token_management.py</div>
                                    <button class="copy-button" onclick="copyCode(this)" data-code="from abstractcore import create_llm
from abstractcore.utils.token_utils import estimate_tokens

# Unified token parameters work across ALL providers
llm = create_llm(
    &quot;anthropic&quot;,
    model=&quot;claude-3-5-haiku-latest&quot;,
    max_tokens=32000,           # Context window (input + output)
    max_output_tokens=8000,     # Maximum output tokens
    max_input_tokens=24000      # Maximum input tokens (auto-calculated if not set)
)

# Token estimation and validation
text = &quot;Your input text here...&quot;
estimated = estimate_tokens(text, model=&quot;claude-3-5-haiku-latest&quot;)
print(f&quot;Estimated tokens: {estimated}&quot;)

# Budget validation with warnings
response = llm.generate(&quot;Write a detailed analysis...&quot;)
print(f&quot;Input tokens: {response.usage.input_tokens}&quot;)
print(f&quot;Output tokens: {response.usage.output_tokens}&quot;)
print(f&quot;Cost estimate: ${response.usage.cost_usd:.4f}&quot;)">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                            <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                            <path d="m5 15-4-4 4-4"></path>
                                            <path d="M5 5a2 2 0 0 0-2 2v6c0 1.1.9 2 2 2h2"></path>
                                        </svg>
                                        Copy
                                    </button>
                                </div>
                                <div class="code-content">
                                    <pre><code class="language-python">from abstractcore import create_llm
from abstractcore.utils.token_utils import estimate_tokens

# Unified token parameters work across ALL providers
llm = create_llm(
    "anthropic",
    model="claude-haiku-4.5",
    max_tokens=32000,           # Context window (input + output)
    max_output_tokens=8000,     # Maximum output tokens
    max_input_tokens=24000      # Maximum input tokens (auto-calculated if not set)
)

# Token estimation and validation
text = "Your input text here..."
estimated = estimate_tokens(text, model="claude-haiku-4.5")
print(f"Estimated tokens: {estimated}")

# Budget validation with warnings
response = llm.generate("Write a detailed analysis...")
print(f"Input tokens: {response.usage.input_tokens}")
print(f"Output tokens: {response.usage.output_tokens}")
print(f"Cost estimate: ${response.usage.cost_usd:.4f}")</code></pre>
                                </div>
                            </div>
                        </div>
                        
                        <div class="demo-panel" id="cli">
                            <div class="code-window">
                                <div class="code-header">
                                    <div class="code-dots">
                                        <span class="dot red"></span>
                                        <span class="dot yellow"></span>
                                        <span class="dot green"></span>
                                    </div>
                                    <div class="code-title">http_server.py</div>
                                    <button class="copy-button" onclick="copyCode(this)" data-code="# Start OpenAI-compatible server
# uvicorn abstractcore.server.app:app --host 0.0.0.0 --port 8000

import openai

client = openai.OpenAI(
    base_url=&quot;http://localhost:8000/v1&quot;,
    api_key=&quot;unused&quot;  # Not required for local providers
)

# Route to any provider using model format: provider/model
response = client.chat.completions.create(
    model=&quot;ollama/qwen3-coder:30b&quot;,      # Ollama provider
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]
)

# Provider discovery via HTTP API
# GET /providers - Complete provider metadata
# GET /providers/ollama/models - Models for specific provider

print(response.choices[0].message.content)">
                                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                            <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                                            <path d="m5 15-4-4 4-4"></path>
                                            <path d="M5 5a2 2 0 0 0-2 2v6c0 1.1.9 2 2 2h2"></path>
                                        </svg>
                                        Copy
                                    </button>
                                </div>
                                <div class="code-content">
                                    <pre><code class="language-python"># Start OpenAI-compatible server
# uvicorn abstractcore.server.app:app --host 0.0.0.0 --port 8000

import openai

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="unused"  # Not required for local providers
)

# Route to any provider using model format: provider/model
response = client.chat.completions.create(
    model="ollama/qwen3-coder:30b",      # Ollama provider
    messages=[{"role": "user", "content": "Hello!"}]
)

# Provider discovery via HTTP API
# GET /providers - Complete provider metadata
# GET /providers/ollama/models - Models for specific provider

print(response.choices[0].message.content)</code></pre>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Providers Section -->
    <section class="providers">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Supported Providers</h2>
                <p class="section-description">
                    One interface for all major LLM providers. Switch between them with a single line change.
                </p>
            </div>
            
            <div class="providers-grid">
                <div class="provider-card">
                    <a href="https://openai.com" target="_blank" class="provider-link">
                        <div class="provider-logo">
                            <img src="assets/providers/openai.svg" alt="OpenAI">
                        </div>
                        <h3 class="provider-name">OpenAI</h3>
                        <p class="provider-description">gpt-5-nano-2025-08-07, GPT-4o, GPT-4o-mini</p>
                        <div class="provider-status">
                            <span class="status-badge status-full">✅ Full Support</span>
                        </div>
                    </a>
                </div>
                
                <div class="provider-card">
                    <a href="https://anthropic.com" target="_blank" class="provider-link">
                        <div class="provider-logo">
                            <img src="assets/providers/anthropic.svg" alt="Anthropic">
                        </div>
                        <h3 class="provider-name">Anthropic</h3>
                        <p class="provider-description">claude-haiku-4.5, Claude 3.5 Sonnet</p>
                        <div class="provider-status">
                            <span class="status-badge status-full">✅ Full Support</span>
                        </div>
                    </a>
                </div>
                
                <div class="provider-card">
                    <a href="https://ollama.com" target="_blank" class="provider-link">
                        <div class="provider-logo">
                            <img src="assets/providers/ollama.svg" alt="Ollama">
                        </div>
                        <h3 class="provider-name">Ollama</h3>
                        <p class="provider-description">qwen3-coder:30b, Local models, privacy-first</p>
                        <div class="provider-status">
                            <span class="status-badge status-full">✅ Full Support</span>
                        </div>
                    </a>
                </div>
                
                <div class="provider-card">
                    <a href="https://lmstudio.ai" target="_blank" class="provider-link">
                        <div class="provider-logo">
                            <img src="assets/providers/lmstudio.svg" alt="LMStudio">
                        </div>
                        <h3 class="provider-name">LMStudio</h3>
                        <p class="provider-description">qwen/qwen3-next-80b, glm-4.5-air-mlx</p>
                        <div class="provider-status">
                            <span class="status-badge status-full">✅ Full Support</span>
                        </div>
                    </a>
                </div>
                
                <div class="provider-card">
                    <a href="https://github.com/ml-explore/mlx" target="_blank" class="provider-link">
                        <div class="provider-logo">
                            <img src="assets/providers/mlx.svg" alt="MLX">
                        </div>
                        <h3 class="provider-name">MLX</h3>
                        <p class="provider-description">mlx-community/gemma-3n-E4B-4bit, mlx-community/Qwen3-4B-Instruct-2507-4bit</p>
                        <div class="provider-status">
                            <span class="status-badge status-full">✅ Full Support</span>
                        </div>
                    </a>
                </div>
                
                <div class="provider-card">
                    <a href="https://huggingface.co" target="_blank" class="provider-link">
                        <div class="provider-logo">
                            <img src="assets/providers/huggingface.svg" alt="HuggingFace">
                        </div>
                        <h3 class="provider-name">HuggingFace</h3>
                        <p class="provider-description">meta-llama/Llama-3.1-8B-Instruct, unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF, Open source models</p>
                        <div class="provider-status">
                            <span class="status-badge status-full">✅ Full Support</span>
                        </div>
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- Documentation Section -->
    <section id="docs" class="documentation">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Comprehensive Documentation</h2>
                <p class="section-description">
                    Everything you need to build production-ready LLM applications. 
                    <strong>AI agents:</strong> Use our optimized <a href="https://www.abstractcore.ai/llms.txt" class="ai-link">llms.txt</a> or <a href="https://www.abstractcore.ai/llms-full.txt" class="ai-link">llms-full.txt</a> for direct integration.
                </p>
            </div>
            
            <div class="docs-grid">
                <div class="doc-category">
                    <h3 class="doc-category-title">🚀 Getting Started</h3>
                    <div class="doc-links">
                        <a href="docs/getting-started.html" class="doc-link">
                            <span class="doc-title">Quick Start Guide</span>
                            <span class="doc-description">5-minute setup and first LLM call</span>
                        </a>
                        <a href="docs/prerequisites.html" class="doc-link">
                            <span class="doc-title">Prerequisites & Setup</span>
                            <span class="doc-description">Install and configure providers</span>
                        </a>
                        <a href="docs/troubleshooting.html" class="doc-link">
                            <span class="doc-title">Troubleshooting</span>
                            <span class="doc-description">Fix common issues quickly</span>
                        </a>
                        <a href="https://www.abstractcore.ai/llms.txt" class="doc-link">
                            <span class="doc-title">🤖 AI Agent Documentation</span>
                            <span class="doc-description">Optimized for AI consumption - concise, actionable examples</span>
                        </a>
                    </div>
                </div>
                
                <div class="doc-category">
                    <h3 class="doc-category-title">📚 Core Library</h3>
                    <div class="doc-links">
                        <a href="docs/api-reference.html" class="doc-link">
                            <span class="doc-title">Python API Reference</span>
                            <span class="doc-description">Complete API documentation</span>
                        </a>
                        <a href="docs/tool-calling.html" class="doc-link">
                            <span class="doc-title">Tool Calling System</span>
                            <span class="doc-description">Universal tools across all providers</span>
                        </a>
                        <a href="docs/session.html" class="doc-link">
                            <span class="doc-title">Session Management</span>
                            <span class="doc-description">Persistent conversations</span>
                        </a>
                        <a href="docs/embeddings.html" class="doc-link">
                            <span class="doc-title">Vector Embeddings</span>
                            <span class="doc-description">Semantic search and RAG</span>
                        </a>
                        <a href="docs/token-management.html" class="doc-link">
                            <span class="doc-title">Token Management</span>
                            <span class="doc-description">Unified parameters and budget validation</span>
                        </a>
                        <a href="https://www.abstractcore.ai/llms-full.txt" class="doc-link">
                            <span class="doc-title">🤖 Complete AI Documentation</span>
                            <span class="doc-description">Full technical reference for AI agents - all features covered</span>
                        </a>
                    </div>
                </div>
                
                <div class="doc-category">
                    <h3 class="doc-category-title">🔧 Advanced</h3>
                    <div class="doc-links">
                        <a href="docs/apps/basic-extractor.html" class="doc-link">
                            <span class="doc-title">CLI Applications</span>
                            <span class="doc-description">Extractor, Judge, Summarizer with debug modes</span>
                        </a>
                        <a href="docs/server.html" class="doc-link">
                            <span class="doc-title">HTTP Server Guide</span>
                            <span class="doc-description">OpenAI-compatible REST API</span>
                        </a>
                        <a href="docs/architecture.html" class="doc-link">
                            <span class="doc-title">Architecture Overview</span>
                            <span class="doc-description">System design and components</span>
                        </a>
                        <a href="docs/capabilities.html" class="doc-link">
                            <span class="doc-title">Capabilities</span>
                            <span class="doc-description">What AbstractCore can do</span>
                        </a>
                        <a href="docs/internal-cli.html" class="doc-link">
                            <span class="doc-title">Internal CLI</span>
                            <span class="doc-description">Built-in testing tool</span>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Examples Section -->
    <section id="examples" class="examples">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Real-World Examples</h2>
                <p class="section-description">
                    Learn from practical examples and use cases.
                </p>
            </div>
            
            <div class="examples-grid">
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Provider Flexibility</h3>
                        <span class="example-badge">Core Feature</span>
                    </div>
                    <p class="example-description">
                        Switch between providers with identical code. Perfect for development vs production environments.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python"># Development (free, local)
llm_dev = create_llm("ollama", model="qwen3:4b")

# Production (high quality, cloud)
llm_prod = create_llm("openai", model="gpt-4o-mini")

# Same interface, different capabilities</code></pre>
                    </div>
                    <a href="docs/examples.html#provider-flexibility" class="example-link">View Full Example →</a>
                </div>
                
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">RAG with Embeddings</h3>
                        <span class="example-badge">Advanced</span>
                    </div>
                    <p class="example-description">
                        Build retrieval-augmented generation systems with built-in embedding support.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-python">from abstractcore.embeddings import EmbeddingManager

embedder = EmbeddingManager()
docs_embeddings = embedder.embed_batch(documents)

# Find most similar document
query_embedding = embedder.embed("user query")
similarity = embedder.compute_similarity(query, docs[0])</code></pre>
                    </div>
                    <a href="docs/examples.html#rag-embeddings" class="example-link">View Full Example →</a>
                </div>
                
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">Universal API Server</h3>
                        <span class="example-badge">Server</span>
                    </div>
                    <p class="example-description">
                        Deploy an OpenAI-compatible API server that works with all providers.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-bash"># Start server
uvicorn abstractcore.server.app:app --port 8000

# Use with any OpenAI client
curl -X POST http://localhost:8000/v1/chat/completions \
  -d '{"model": "ollama/qwen3-coder:30b", ...}'</code></pre>
                    </div>
                    <a href="docs/examples.html#api-server" class="example-link">View Full Example →</a>
                </div>
                
                <div class="example-card">
                    <div class="example-header">
                        <h3 class="example-title">CLI Apps & Debug Mode</h3>
                        <span class="example-badge">New</span>
                    </div>
                    <p class="example-description">
                        Ready-to-use terminal tools with debug capabilities and focus areas for targeted processing.
                    </p>
                    <div class="example-code">
                        <pre><code class="language-bash"># Extract knowledge with debug mode
extractor document.pdf --format json-ld --debug --iterate 3

# Evaluate with focus areas
judge README.md --focus "examples, completeness" --debug

# Self-healing JSON handles truncated responses automatically</code></pre>
                    </div>
                    <a href="docs/apps/basic-extractor.html" class="example-link">View CLI Docs →</a>
                </div>
            </div>
            
            <div class="examples-cta">
                <a href="docs/examples.html" class="btn btn-primary">
                    View All Examples
                    <svg class="btn-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M5 12h14"/>
                        <path d="M12 5l7 7-7 7"/>
                    </svg>
                </a>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <div class="footer-brand">
                        <img src="assets/logo.svg" alt="AbstractCore" class="footer-logo">
                        <span class="footer-brand-text">AbstractCore</span>
                    </div>
                    <p class="footer-description">
                        Unified LLM provider interface for Python. Write once, run everywhere.
                    </p>
                    <div class="footer-social">
                        <a href="https://github.com/lpalbou/AbstractCore" class="social-link" target="_blank" aria-label="GitHub">
                            <svg viewBox="0 0 24 24" fill="currentColor">
                                <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                            </svg>
                        </a>
                    </div>
                </div>
                
                <div class="footer-section">
                    <h4 class="footer-title">Documentation</h4>
                    <ul class="footer-links">
                        <li><a href="docs/getting-started.html">Getting Started</a></li>
                        <li><a href="docs/api-reference.html">API Reference</a></li>
                        <li><a href="docs/examples.html">Examples</a></li>
                        <li><a href="docs/troubleshooting.html">Troubleshooting</a></li>
                    </ul>
                </div>
                
                <div class="footer-section">
                    <h4 class="footer-title">Resources</h4>
                    <ul class="footer-links">
                        <li><a href="https://github.com/lpalbou/AbstractCore" target="_blank">GitHub Repository</a></li>
                        <li><a href="https://github.com/lpalbou/AbstractCore/issues" target="_blank">Report Issues</a></li>
                        <li><a href="https://github.com/lpalbou/AbstractCore/discussions" target="_blank">Discussions</a></li>
                        <li><a href="https://www.abstractcore.ai/llms.txt">LLMs.txt</a></li>
                    </ul>
                </div>
                
                <div class="footer-section">
                    <h4 class="footer-title">Community</h4>
                    <ul class="footer-links">
                        <li><a href="docs/contributing.html">Contributing</a></li>
                        <li><a href="docs/changelog.html">Changelog</a></li>
                        <li><a href="docs/acknowledgements.html">Acknowledgements</a></li>
                        <li><a href="https://github.com/lpalbou/AbstractCore/blob/main/LICENSE" target="_blank">MIT License</a></li>
                        <li><a href="mailto:contact@abstractcore.ai">Contact Us</a></li>
                    </ul>
                </div>
            </div>
            
            <div class="footer-bottom">
                <div class="footer-copyright">
                    <p>&copy; 2025 AbstractCore. Licensed under MIT License.</p>
                </div>
                <div class="footer-meta">
                    <span>Made with ❤️ for the AI community</span>
                </div>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="assets/js/main.js"></script>
</body>
</html>
