{"version": "2.4.0", "debug_mode": true, "event": "\ud83d\ude80 AbstractCore Server Starting", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:03:20.059568Z"}
{"request_id": "b49041ab", "provider": "ollama", "model": "qwen3-coder:30b", "messages": 4, "has_tools": false, "stream": false, "event": "\ud83d\udce5 Chat Completion Request", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:03:20.588589Z"}
{"request_id": "b49041ab", "target_format": "qwen3", "user_agent": "python-httpx/0.27.2", "event": "\ud83c\udfaf Target Format Detected", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:03:20.588731Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_tokens 32768 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:03:20.824472Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_output_tokens 8192 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:03:20.824558Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Initialized tool handler for qwen3-coder:30b: architecture=qwen3_moe, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x362bc00e0>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:03:22 GMT'), (b'Content-Length', b'674')])
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Generation completed for qwen3-coder:30b: 1944.26ms (tokens: 120)", "logger": "OllamaProvider", "level": "info", "timestamp": "2025-10-15T19:03:22.773647Z"}
Detected architecture 'qwen3_moe' for model 'ollama/qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected 0 tool calls in content
{"request_id": "0ff9fa91", "provider": "ollama", "model": "qwen3-coder:30b", "messages": 4, "has_tools": false, "stream": false, "event": "\ud83d\udce5 Chat Completion Request", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:03:22.781247Z"}
{"request_id": "0ff9fa91", "target_format": "qwen3", "user_agent": "python-httpx/0.27.2", "event": "\ud83c\udfaf Target Format Detected", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:03:22.781373Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_tokens 32768 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:03:22.781611Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_output_tokens 8192 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:03:22.781691Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Initialized tool handler for qwen3-coder:30b: architecture=qwen3_moe, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x362bc0950>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:03:23 GMT'), (b'Content-Length', b'787')])
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Generation completed for qwen3-coder:30b: 1201.73ms (tokens: 142)", "logger": "OllamaProvider", "level": "info", "timestamp": "2025-10-15T19:03:23.988374Z"}
Detected architecture 'qwen3_moe' for model 'ollama/qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected 0 tool calls in content
