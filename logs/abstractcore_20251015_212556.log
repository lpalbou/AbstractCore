{"version": "2.4.0", "debug_mode": true, "event": "\ud83d\ude80 AbstractCore Server Starting", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:25:56.044049Z"}
{"event": "Listed 3 models from all providers", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:25:56.427707Z"}
{"request_id": "c2e07666", "provider": "ollama", "model": "qwen3-coder:30b", "messages": 4, "has_tools": false, "stream": false, "event": "\ud83d\udce5 Chat Completion Request", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:25:56.445070Z"}
{"request_id": "c2e07666", "target_format": "qwen3", "user_agent": "python-httpx/0.27.2", "event": "\ud83c\udfaf Target Format Detected", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:25:56.445199Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_tokens 32768 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:25:56.643412Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_output_tokens 8192 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:25:56.643496Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Initialized tool handler for qwen3-coder:30b: architecture=qwen3_moe, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x173fc0290>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:25:58 GMT'), (b'Content-Length', b'787')])
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Generation completed for qwen3-coder:30b: 2073.83ms (tokens: 300)", "logger": "OllamaProvider", "level": "info", "timestamp": "2025-10-15T19:25:58.721851Z"}
Detected architecture 'qwen3_moe' for model 'ollama/qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected 0 tool calls in content
{"request_id": "e3a9abb2", "provider": "ollama", "model": "qwen3-coder:30b", "messages": 4, "has_tools": false, "stream": false, "event": "\ud83d\udce5 Chat Completion Request", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:25:58.729014Z"}
{"request_id": "e3a9abb2", "target_format": "qwen3", "user_agent": "python-httpx/0.27.2", "event": "\ud83c\udfaf Target Format Detected", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:25:58.729088Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_tokens 32768 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:25:58.729321Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_output_tokens 8192 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:25:58.729389Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Initialized tool handler for qwen3-coder:30b: architecture=qwen3_moe, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x173fc0bc0>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:26:01 GMT'), (b'Content-Length', b'1433')])
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Generation completed for qwen3-coder:30b: 3110.85ms (tokens: 342)", "logger": "OllamaProvider", "level": "info", "timestamp": "2025-10-15T19:26:01.845161Z"}
Detected architecture 'qwen3_moe' for model 'ollama/qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected 0 tool calls in content
{"request_id": "d27917c0", "provider": "ollama", "model": "qwen3-coder:30b", "messages": 6, "has_tools": false, "stream": false, "event": "\ud83d\udce5 Chat Completion Request", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:26:01.852025Z"}
{"request_id": "d27917c0", "target_format": "qwen3", "user_agent": "python-httpx/0.27.2", "event": "\ud83c\udfaf Target Format Detected", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:26:01.852111Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_tokens 32768 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:26:01.852323Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_output_tokens 8192 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:26:01.852387Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Initialized tool handler for qwen3-coder:30b: architecture=qwen3_moe, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x173fc18b0>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:26:03 GMT'), (b'Content-Length', b'1227')])
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Generation completed for qwen3-coder:30b: 2030.16ms (tokens: 286)", "logger": "OllamaProvider", "level": "info", "timestamp": "2025-10-15T19:26:03.887265Z"}
Detected architecture 'qwen3_moe' for model 'ollama/qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected 0 tool calls in content
{"request_id": "bbab8fff", "provider": "ollama", "model": "qwen3-coder:30b", "messages": 6, "has_tools": false, "stream": false, "event": "\ud83d\udce5 Chat Completion Request", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:26:03.897648Z"}
{"request_id": "bbab8fff", "target_format": "qwen3", "user_agent": "python-httpx/0.27.2", "event": "\ud83c\udfaf Target Format Detected", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:26:03.897777Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_tokens 32768 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:26:03.898092Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_output_tokens 8192 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:26:03.898184Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Initialized tool handler for qwen3-coder:30b: architecture=qwen3_moe, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x173fc24e0>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:26:04 GMT'), (b'Content-Length', b'367')])
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Generation completed for qwen3-coder:30b: 306.56ms (tokens: 97)", "logger": "OllamaProvider", "level": "info", "timestamp": "2025-10-15T19:26:04.211509Z"}
Detected architecture 'qwen3_moe' for model 'ollama/qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected 0 tool calls in content
