{"version": "2.4.0", "debug_mode": false, "event": "\ud83d\ude80 AbstractCore Server Starting", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:14:49.404055Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x369b96fc0>, 'json_data': None}
Sending HTTP Request: GET https://api.openai.com/v1/models
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e622a20>
start_tls.started ssl_context=<ssl.SSLContext object at 0x36db5c3d0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e471d00>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 19:14:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'8b0d010ea72cd48b5a03cb210ae2892e'), (b'openai-processing-ms', b'307'), (b'x-envoy-upstream-service-time', b'310'), (b'x-openai-proxy-wasm', b'v0.1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TrTzEdVz3WORrkmZ8061H4jCRcqW40xyySpa51HZ680-1760555691-1.0.1.1-dn._OGARSjefomD2EeVavUeltfulvKH.6Rv.lbXv9rEHgIEkg5eeU3IJ5vztHQ8nf1S3H_Ff0Y99G0jBYLkfSv.1Q6pIQ227pUFDCD4Rnzc; path=/; expires=Wed, 15-Oct-25 19:44:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=aFwTD2C2LpmHug8uJ36fMYKOf677dIpLPSmLMaIpwaM-1760555691901-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f1a44f2cd2d6de-CDG'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: GET https://api.openai.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: GET https://api.openai.com/v1/models "200 OK" Headers([('date', 'Wed, 15 Oct 2025 19:14:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-version', '2020-10-01'), ('x-request-id', '8b0d010ea72cd48b5a03cb210ae2892e'), ('openai-processing-ms', '307'), ('x-envoy-upstream-service-time', '310'), ('x-openai-proxy-wasm', 'v0.1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=TrTzEdVz3WORrkmZ8061H4jCRcqW40xyySpa51HZ680-1760555691-1.0.1.1-dn._OGARSjefomD2EeVavUeltfulvKH.6Rv.lbXv9rEHgIEkg5eeU3IJ5vztHQ8nf1S3H_Ff0Y99G0jBYLkfSv.1Q6pIQ227pUFDCD4Rnzc; path=/; expires=Wed, 15-Oct-25 19:44:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=aFwTD2C2LpmHug8uJ36fMYKOf677dIpLPSmLMaIpwaM-1760555691901-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98f1a44f2cd2d6de-CDG'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: 8b0d010ea72cd48b5a03cb210ae2892e
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
{"event": "Using max_tokens 200000 from model capabilities for claude-3-haiku-20240307", "logger": "AnthropicProvider", "level": "debug", "timestamp": "2025-10-15T19:14:52.065333Z"}
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
{"event": "Using max_output_tokens 4096 from model capabilities for claude-3-haiku-20240307", "logger": "AnthropicProvider", "level": "debug", "timestamp": "2025-10-15T19:14:52.065458Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Initialized tool handler for claude-3-haiku-20240307: architecture=claude, native=True, prompted=True
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=10.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e657080>
start_tls.started ssl_context=<ssl.SSLContext object at 0x36dbebbd0> server_hostname='api.anthropic.com' timeout=10.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e656f90>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 19:14:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'request-id', b'req_011CU9X2Yv8xCuacxvFsSi9g'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'anthropic-organization-id', b'5f4c7d27-265b-4b46-9dfd-715a0704d0dd'), (b'x-envoy-upstream-service-time', b'57'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f1a453ebc82068-CDG')])
HTTP Request: GET https://api.anthropic.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
close.started
close.complete
{"event": "Retrieved 11 models from Anthropic API", "logger": "AnthropicProvider", "level": "debug", "timestamp": "2025-10-15T19:14:52.299964Z"}
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
{"event": "Using max_tokens 16384 from model capabilities for llama2", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:14:52.301965Z"}
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
{"event": "Using max_output_tokens 4096 from model capabilities for llama2", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:14:52.302124Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Initialized tool handler for llama2: architecture=llama2, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e622ff0>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:14:52 GMT'), (b'Transfer-Encoding', b'chunked')])
HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
{"event": "Using max_tokens 16384 from model capabilities for local-model", "logger": "LMStudioProvider", "level": "debug", "timestamp": "2025-10-15T19:14:52.321112Z"}
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
{"event": "Using max_output_tokens 4096 from model capabilities for local-model", "logger": "LMStudioProvider", "level": "debug", "timestamp": "2025-10-15T19:14:52.321231Z"}
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Initialized tool handler for local-model: architecture=generic, native=False, prompted=True
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
connect_tcp.started host='localhost' port=1234 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e6566f0>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'X-Powered-By', b'Express'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'2031'), (b'ETag', b'W/"7ef-pbA2GS939+S95haqqRBYCdzO9GI"'), (b'Date', b'Wed, 15 Oct 2025 19:14:52 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
HTTP Request: GET http://localhost:1234/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Listed 115 models from all providers", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:14:52.336634Z"}
