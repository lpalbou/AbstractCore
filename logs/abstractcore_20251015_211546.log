{"version": "2.4.0", "debug_mode": true, "event": "\ud83d\ude80 AbstractCore Server Starting", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:15:46.862626Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x36a097060>, 'json_data': None}
Sending HTTP Request: GET https://api.openai.com/v1/models
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e222780>
start_tls.started ssl_context=<ssl.SSLContext object at 0x36d85c3d0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e1f10a0>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 19:15:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'de214cc80cbdef7cc08de8b45b94b0d1'), (b'openai-processing-ms', b'260'), (b'x-envoy-upstream-service-time', b'262'), (b'x-openai-proxy-wasm', b'v0.1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=..NJ_f9CrLMsc7An_2Iq1oEN6bq6Cr4tj9Qz2GlB2ls-1760555747-1.0.1.1-05y0AEss.R9F7sGzFXPlI8P3qmqWIzapE0FBWGhQhFpthD8x.6si5RdNNW5s5o_Rnnih.LCuwjAWIM4pCZh4Att7ibRHWiIKXU0kv3fsodQ; path=/; expires=Wed, 15-Oct-25 19:45:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=NOhnlqINEt_t67MIa7wWBcWh1gcjy2GK55GTh2Dfb3I-1760555747799-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f1a5ad3af93ce1-CDG'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: GET https://api.openai.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: GET https://api.openai.com/v1/models "200 OK" Headers([('date', 'Wed, 15 Oct 2025 19:15:47 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-version', '2020-10-01'), ('x-request-id', 'de214cc80cbdef7cc08de8b45b94b0d1'), ('openai-processing-ms', '260'), ('x-envoy-upstream-service-time', '262'), ('x-openai-proxy-wasm', 'v0.1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=..NJ_f9CrLMsc7An_2Iq1oEN6bq6Cr4tj9Qz2GlB2ls-1760555747-1.0.1.1-05y0AEss.R9F7sGzFXPlI8P3qmqWIzapE0FBWGhQhFpthD8x.6si5RdNNW5s5o_Rnnih.LCuwjAWIM4pCZh4Att7ibRHWiIKXU0kv3fsodQ; path=/; expires=Wed, 15-Oct-25 19:45:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=NOhnlqINEt_t67MIa7wWBcWh1gcjy2GK55GTh2Dfb3I-1760555747799-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98f1a5ad3af93ce1-CDG'), ('content-encoding', 'br'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: de214cc80cbdef7cc08de8b45b94b0d1
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
{"event": "Using max_tokens 200000 from model capabilities for claude-3-haiku-20240307", "logger": "AnthropicProvider", "level": "debug", "timestamp": "2025-10-15T19:15:47.904877Z"}
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
{"event": "Using max_output_tokens 4096 from model capabilities for claude-3-haiku-20240307", "logger": "AnthropicProvider", "level": "debug", "timestamp": "2025-10-15T19:15:47.905140Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Initialized tool handler for claude-3-haiku-20240307: architecture=claude, native=True, prompted=True
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=10.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e253500>
start_tls.started ssl_context=<ssl.SSLContext object at 0x36d8ebbd0> server_hostname='api.anthropic.com' timeout=10.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e252f60>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 19:15:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'request-id', b'req_011CU9X6faLexXjFXqVt1c8c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'anthropic-organization-id', b'5f4c7d27-265b-4b46-9dfd-715a0704d0dd'), (b'x-envoy-upstream-service-time', b'25'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f1a5b0cd0401bb-CDG')])
HTTP Request: GET https://api.anthropic.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
close.started
close.complete
{"event": "Retrieved 11 models from Anthropic API", "logger": "AnthropicProvider", "level": "debug", "timestamp": "2025-10-15T19:15:48.096012Z"}
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
{"event": "Using max_tokens 16384 from model capabilities for llama2", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:15:48.098312Z"}
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
{"event": "Using max_output_tokens 4096 from model capabilities for llama2", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:15:48.098579Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Initialized tool handler for llama2: architecture=llama2, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e222ff0>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:15:48 GMT'), (b'Transfer-Encoding', b'chunked')])
HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
{"event": "Using max_tokens 16384 from model capabilities for local-model", "logger": "LMStudioProvider", "level": "debug", "timestamp": "2025-10-15T19:15:48.113995Z"}
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
{"event": "Using max_output_tokens 4096 from model capabilities for local-model", "logger": "LMStudioProvider", "level": "debug", "timestamp": "2025-10-15T19:15:48.114071Z"}
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Initialized tool handler for local-model: architecture=generic, native=False, prompted=True
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
connect_tcp.started host='localhost' port=1234 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e253da0>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'X-Powered-By', b'Express'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'2031'), (b'ETag', b'W/"7ef-pbA2GS939+S95haqqRBYCdzO9GI"'), (b'Date', b'Wed, 15 Oct 2025 19:15:48 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
HTTP Request: GET http://localhost:1234/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Listed 115 models from all providers", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:15:48.122036Z"}
{"request_id": "c8fa0613", "provider": "ollama", "model": "qwen3-coder:30b", "messages": 4, "has_tools": false, "stream": false, "event": "\ud83d\udce5 Chat Completion Request", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:15:48.134782Z"}
{"request_id": "c8fa0613", "target_format": "qwen3", "user_agent": "python-httpx/0.27.2", "event": "\ud83c\udfaf Target Format Detected", "logger": "server", "level": "info", "timestamp": "2025-10-15T19:15:48.134919Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_tokens 32768 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:15:48.135322Z"}
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
{"event": "Using max_output_tokens 8192 from model capabilities for qwen3-coder:30b", "logger": "OllamaProvider", "level": "debug", "timestamp": "2025-10-15T19:15:48.135423Z"}
load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/opt/anaconda3/lib/python3.12/site-packages/certifi/cacert.pem'
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected architecture 'qwen3_moe' for model 'qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Using capabilities from 'qwen3' for 'qwen3-coder:30b'
Initialized tool handler for qwen3-coder:30b: architecture=qwen3_moe, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x36e284bf0>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 19:15:56 GMT'), (b'Content-Length', b'786')])
HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
{"event": "Generation completed for qwen3-coder:30b: 8128.66ms (tokens: 313)", "logger": "OllamaProvider", "level": "info", "timestamp": "2025-10-15T19:15:56.268532Z"}
Detected architecture 'qwen3_moe' for model 'ollama/qwen3-coder:30b' (pattern: 'qwen3-coder:30b')
Detected 0 tool calls in content
close.started
close.complete
