ðŸš€ AbstractCore Server Starting | version=2.4.0, debug_mode=False
Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x105a48ea0>, 'json_data': None}
Sending HTTP Request: GET https://api.openai.com/v1/models
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1110d5ac0>
start_tls.started ssl_context=<ssl.SSLContext object at 0x107e781d0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1110a6450>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.failed exception=ReadTimeout(TimeoutError('The read operation timed out'))
response_closed.started
response_closed.complete
Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 136, in handle_request
    raise exc
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 126, in read
    with map_exceptions(exc_map):
  File "/opt/anaconda3/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/opt/anaconda3/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/Users/albou/projects/abstractllm_core/.venv/lib/python3.12/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out
2 retries left
Retrying request to /models in 0.422527 seconds
Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x105a48ea0>, 'json_data': None}
Sending HTTP Request: GET https://api.openai.com/v1/models
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1110d7500>
start_tls.started ssl_context=<ssl.SSLContext object at 0x107e781d0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1110d7410>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 20:17:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'58110b1f292028d5375f7f210a680a1e'), (b'openai-processing-ms', b'483'), (b'x-envoy-upstream-service-time', b'489'), (b'x-openai-proxy-wasm', b'v0.1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=D7OMiGkfJGo5ZHdT_aPfI.OTCh4RW4SmlAntGDG6jhc-1760559431-1.0.1.1-4kCirnQ1Aty5NrTK6V.P7lvUS16faffdeUWVkC.wSyG.lwVnqRKymqW65.eiURIfmKf5yL5h9jOgWBeFVfh4YBI1Dl6uDR2lktiWfF4CGmo; path=/; expires=Wed, 15-Oct-25 20:47:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=yRnVGZI10yAawUQnn7XUHxZjPyg8p1SStZ30vkzR81s-1760559431840-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f1ff9acabf6f69-CDG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: GET https://api.openai.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: GET https://api.openai.com/v1/models "200 OK" Headers([('date', 'Wed, 15 Oct 2025 20:17:11 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-version', '2020-10-01'), ('x-request-id', '58110b1f292028d5375f7f210a680a1e'), ('openai-processing-ms', '483'), ('x-envoy-upstream-service-time', '489'), ('x-openai-proxy-wasm', 'v0.1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=D7OMiGkfJGo5ZHdT_aPfI.OTCh4RW4SmlAntGDG6jhc-1760559431-1.0.1.1-4kCirnQ1Aty5NrTK6V.P7lvUS16faffdeUWVkC.wSyG.lwVnqRKymqW65.eiURIfmKf5yL5h9jOgWBeFVfh4YBI1Dl6uDR2lktiWfF4CGmo; path=/; expires=Wed, 15-Oct-25 20:47:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=yRnVGZI10yAawUQnn7XUHxZjPyg8p1SStZ30vkzR81s-1760559431840-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98f1ff9acabf6f69-CDG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: 58110b1f292028d5375f7f210a680a1e
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Using max_tokens 200000 from model capabilities for claude-3-haiku-20240307
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Using max_output_tokens 4096 from model capabilities for claude-3-haiku-20240307
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Using max_tokens 16384 from model capabilities for llama2
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Using max_output_tokens 4096 from model capabilities for llama2
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Initialized tool handler for llama2: architecture=llama2, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111276750>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 20:17:12 GMT'), (b'Transfer-Encoding', b'chunked')])
HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Using max_tokens 16384 from model capabilities for local-model
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Using max_output_tokens 4096 from model capabilities for local-model
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Initialized tool handler for local-model: architecture=generic, native=False, prompted=True
connect_tcp.started host='localhost' port=1234 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111277200>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'X-Powered-By', b'Express'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'2031'), (b'ETag', b'W/"7ef-O/BIVkj5ElTI8MjJKLvz9dk9XHI"'), (b'Date', b'Wed, 15 Oct 2025 20:17:12 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
HTTP Request: GET http://localhost:1234/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
Listed 83 models from all providers (type=text-generation)
Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x1110f60c0>, 'json_data': None}
Sending HTTP Request: GET https://api.openai.com/v1/models
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112763c0>
start_tls.started ssl_context=<ssl.SSLContext object at 0x105a03cd0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1105ae390>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 20:17:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'68d9629b8424099a3dd032adbb660fa0'), (b'openai-processing-ms', b'233'), (b'x-envoy-upstream-service-time', b'236'), (b'x-openai-proxy-wasm', b'v0.1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PvikKvXBN8yEsq6q3DjObJKureuP_MS37yflZbHVtrc-1760559436-1.0.1.1-a.YqJXnmwgO97HHsLOPfjYZBPxXxAAa_9PMRygnlgZdXNTGeMI7nE87OAEUyO5dxohYhuXy0xUp8HXOJGKb_YLrwaQcsOIfoT2c.CZfqrak; path=/; expires=Wed, 15-Oct-25 20:47:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4EdlmCo6bV4h_pE5zDzp7SF3a7lJvtkB_yQJTfFPvK4-1760559436939-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f1ffbe3b9fbb45-CDG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: GET https://api.openai.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: GET https://api.openai.com/v1/models "200 OK" Headers([('date', 'Wed, 15 Oct 2025 20:17:16 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-version', '2020-10-01'), ('x-request-id', '68d9629b8424099a3dd032adbb660fa0'), ('openai-processing-ms', '233'), ('x-envoy-upstream-service-time', '236'), ('x-openai-proxy-wasm', 'v0.1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=PvikKvXBN8yEsq6q3DjObJKureuP_MS37yflZbHVtrc-1760559436-1.0.1.1-a.YqJXnmwgO97HHsLOPfjYZBPxXxAAa_9PMRygnlgZdXNTGeMI7nE87OAEUyO5dxohYhuXy0xUp8HXOJGKb_YLrwaQcsOIfoT2c.CZfqrak; path=/; expires=Wed, 15-Oct-25 20:47:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4EdlmCo6bV4h_pE5zDzp7SF3a7lJvtkB_yQJTfFPvK4-1760559436939-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98f1ffbe3b9fbb45-CDG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: 68d9629b8424099a3dd032adbb660fa0
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Using max_tokens 200000 from model capabilities for claude-3-haiku-20240307
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Using max_output_tokens 4096 from model capabilities for claude-3-haiku-20240307
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Using max_tokens 16384 from model capabilities for llama2
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Using max_output_tokens 4096 from model capabilities for llama2
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Initialized tool handler for llama2: architecture=llama2, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1110d7bc0>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 20:17:17 GMT'), (b'Transfer-Encoding', b'chunked')])
HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Using max_tokens 16384 from model capabilities for local-model
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Using max_output_tokens 4096 from model capabilities for local-model
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Initialized tool handler for local-model: architecture=generic, native=False, prompted=True
connect_tcp.started host='localhost' port=1234 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111277b60>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'X-Powered-By', b'Express'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'2031'), (b'ETag', b'W/"7ef-O/BIVkj5ElTI8MjJKLvz9dk9XHI"'), (b'Date', b'Wed, 15 Oct 2025 20:17:17 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
HTTP Request: GET http://localhost:1234/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
Listed 22 models from all providers (type=text-embedding)
Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x105a489a0>, 'json_data': None}
Sending HTTP Request: GET https://api.openai.com/v1/models
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112ad730>
start_tls.started ssl_context=<ssl.SSLContext object at 0x110121bd0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112ad580>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 20:17:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'5263a969f864cdeff58f2f5eb6157e6b'), (b'openai-processing-ms', b'406'), (b'x-envoy-upstream-service-time', b'410'), (b'x-openai-proxy-wasm', b'v0.1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Sy9OgFsqB6MnGYnXc8IKZfOcMVAYMBl9BSS2M8RAreE-1760559447-1.0.1.1-O4KEfE5UZQsrWBDAFDr5prYwojmY9zuz.NmrrhaneFy9k2TgYyXajIldYvqxks5s8WNtv32rJsqOlg.Bi05L5TACKeRGgSTTy_LQiEUrP6M; path=/; expires=Wed, 15-Oct-25 20:47:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=EMovGBDahPmhNmA3MZ9eP2.4dL8R7jBJbUdlmTgy9pI-1760559447680-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f200004ac802bf-CDG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: GET https://api.openai.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: GET https://api.openai.com/v1/models "200 OK" Headers([('date', 'Wed, 15 Oct 2025 20:17:27 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-version', '2020-10-01'), ('x-request-id', '5263a969f864cdeff58f2f5eb6157e6b'), ('openai-processing-ms', '406'), ('x-envoy-upstream-service-time', '410'), ('x-openai-proxy-wasm', 'v0.1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Sy9OgFsqB6MnGYnXc8IKZfOcMVAYMBl9BSS2M8RAreE-1760559447-1.0.1.1-O4KEfE5UZQsrWBDAFDr5prYwojmY9zuz.NmrrhaneFy9k2TgYyXajIldYvqxks5s8WNtv32rJsqOlg.Bi05L5TACKeRGgSTTy_LQiEUrP6M; path=/; expires=Wed, 15-Oct-25 20:47:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=EMovGBDahPmhNmA3MZ9eP2.4dL8R7jBJbUdlmTgy9pI-1760559447680-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98f200004ac802bf-CDG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: 5263a969f864cdeff58f2f5eb6157e6b
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Using max_tokens 200000 from model capabilities for claude-3-haiku-20240307
Detected architecture 'claude' for model 'claude-3-haiku-20240307' (pattern: 'claude')
Using capabilities from 'claude-3-haiku' for 'claude-3-haiku-20240307'
Using max_output_tokens 4096 from model capabilities for claude-3-haiku-20240307
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Using max_tokens 16384 from model capabilities for llama2
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Using max_output_tokens 4096 from model capabilities for llama2
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Detected architecture 'llama2' for model 'llama2' (pattern: 'llama2')
Using default capabilities for 'llama2' (architecture: llama2)
Initialized tool handler for llama2: architecture=llama2, native=False, prompted=True
connect_tcp.started host='localhost' port=11434 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112aea80>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 15 Oct 2025 20:17:27 GMT'), (b'Transfer-Encoding', b'chunked')])
HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Using max_tokens 16384 from model capabilities for local-model
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Using max_output_tokens 4096 from model capabilities for local-model
No specific architecture detected for 'local-model', using generic
No specific architecture detected for 'local-model', using generic
Using default capabilities for 'local-model' (architecture: generic)
Initialized tool handler for local-model: architecture=generic, native=False, prompted=True
connect_tcp.started host='localhost' port=1234 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112af530>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'X-Powered-By', b'Express'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'2031'), (b'ETag', b'W/"7ef-O/BIVkj5ElTI8MjJKLvz9dk9XHI"'), (b'Date', b'Wed, 15 Oct 2025 20:17:27 GMT'), (b'Connection', b'keep-alive'), (b'Keep-Alive', b'timeout=5')])
HTTP Request: GET http://localhost:1234/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
Listed 5 available providers
ðŸ“¥ Chat Completion Request | request_id=127cfd8e, provider=openai, model=gpt-4, messages=1, has_tools=True, stream=False
Invalid agent_format 'auto', using auto-detection
ðŸŽ¯ Target Format Detected | request_id=127cfd8e, target_format=passthrough, user_agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:1
Detected architecture 'gpt' for model 'gpt-4' (pattern: 'gpt')
Detected architecture 'gpt' for model 'gpt-4' (pattern: 'gpt')
Detected architecture 'gpt' for model 'gpt-4' (pattern: 'gpt')
Using max_tokens 128000 from model capabilities for gpt-4
Detected architecture 'gpt' for model 'gpt-4' (pattern: 'gpt')
Using max_output_tokens 4096 from model capabilities for gpt-4
Detected architecture 'gpt' for model 'gpt-4' (pattern: 'gpt')
Detected architecture 'gpt' for model 'gpt-4' (pattern: 'gpt')
Initialized tool handler for gpt-4: architecture=gpt, native=True, prompted=True
Request options: {'method': 'get', 'url': '/models', 'post_parser': <function SyncAPIClient._request_api_list.<locals>._parser at 0x1067b9ee0>, 'json_data': None}
Sending HTTP Request: GET https://api.openai.com/v1/models
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111277b60>
start_tls.started ssl_context=<ssl.SSLContext object at 0x1112639d0> server_hostname='api.openai.com' timeout=None
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112ac050>
send_request_headers.started request=<Request [b'GET']>
send_request_headers.complete
send_request_body.started request=<Request [b'GET']>
send_request_body.complete
receive_response_headers.started request=<Request [b'GET']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 20:17:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'x-request-id', b'ee55ee388b08ce7bae09773ebb4e3f7c'), (b'openai-processing-ms', b'230'), (b'x-envoy-upstream-service-time', b'232'), (b'x-openai-proxy-wasm', b'v0.1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nQAJQCkBSmTLLw5S3prNmUtqbcprCvrgMiw4KrZmDYg-1760559460-1.0.1.1-Fu76kVdpzTwyWG1yPX_BbO_axjLtmmJ.aH5jLqvKZWHQVNxCAswxwcqUZFELnYMkUpJU7oH_yz6wcIwa5emvjSbxRQf.VG8cnVnqEJV.8Xs; path=/; expires=Wed, 15-Oct-25 20:47:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=cdnXImWrf2idSxpvbFqUZ8i0alzPsSpAHCTg6umMaVU-1760559460902-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f200549f80e74e-CDG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: GET https://api.openai.com/v1/models "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'GET']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: GET https://api.openai.com/v1/models "200 OK" Headers([('date', 'Wed, 15 Oct 2025 20:17:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-version', '2020-10-01'), ('x-request-id', 'ee55ee388b08ce7bae09773ebb4e3f7c'), ('openai-processing-ms', '230'), ('x-envoy-upstream-service-time', '232'), ('x-openai-proxy-wasm', 'v0.1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=nQAJQCkBSmTLLw5S3prNmUtqbcprCvrgMiw4KrZmDYg-1760559460-1.0.1.1-Fu76kVdpzTwyWG1yPX_BbO_axjLtmmJ.aH5jLqvKZWHQVNxCAswxwcqUZFELnYMkUpJU7oH_yz6wcIwa5emvjSbxRQf.VG8cnVnqEJV.8Xs; path=/; expires=Wed, 15-Oct-25 20:47:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=cdnXImWrf2idSxpvbFqUZ8i0alzPsSpAHCTg6umMaVU-1760559460902-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '98f200549f80e74e-CDG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: ee55ee388b08ce7bae09773ebb4e3f7c
Tool execution disabled - tools will be generated but not executed
Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-be90cd34-f875-470c-bc09-85e198338aa1', 'json_data': {'messages': [{'role': 'user', 'content': 'What is the capital of France?'}], 'model': 'gpt-4', 'frequency_penalty': 0.0, 'max_tokens': 4096, 'presence_penalty': 0.0, 'stream': False, 'temperature': 0.7, 'tool_choice': 'auto', 'tools': [], 'top_p': 1.0}}
Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 15 Oct 2025 20:17:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-ykmu0wo8hycgkr4dz3cu7xon'), (b'openai-processing-ms', b'737'), (b'openai-project', b'proj_FVZMLPQVPcScMncEVyt3iBjA'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'780'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9990'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'60ms'), (b'x-request-id', b'req_3d3b4ce3db314449a24b2f0171e9dd1c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'98f20057bc7ce74e-CDG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 15 Oct 2025 20:17:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-ykmu0wo8hycgkr4dz3cu7xon', 'openai-processing-ms': '737', 'openai-project': 'proj_FVZMLPQVPcScMncEVyt3iBjA', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '780', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9990', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '60ms', 'x-request-id': 'req_3d3b4ce3db314449a24b2f0171e9dd1c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '98f20057bc7ce74e-CDG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
request_id: req_3d3b4ce3db314449a24b2f0171e9dd1c
Initialized qwen3 tag rewriter for model gpt-4
rewrite_text called with text: The capital of France is Paris.
Target output tags: start='<|tool_call|>', end='</|tool_call|>'
Starting pattern matching with 5 patterns
Pattern 0: <\|tool_call\|>\s*(.*?)\s*</\|tool_call\|>... - found 0 matches
Pattern 1: <function_call>\s*(.*?)\s*</function_call>... - found 0 matches
Pattern 2: <tool_call>\s*(.*?)\s*</tool_call>... - found 0 matches
Pattern 3: ```tool_code\s*\n(.*?)\n```... - found 0 matches
Pattern 4: (?<![<])(\{[^{}]*["\']name["\'][^{}]*(?:\{[^{}]*\}... - found 0 matches
Final rewritten text: The capital of France is Paris.
Tag rewriting had no effect on: The capital of France is Paris.
Generation completed for gpt-4: 984.05ms (tokens: 38)
close.started
close.complete
close.started
close.complete
close.started
close.complete
close.started
close.complete
