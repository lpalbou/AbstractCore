# AbstractCore

> Unified Python interface for cloud + local LLM providers with streaming, tool calling, media/vision input handling, structured output, centralized configuration, and an optional OpenAI-compatible HTTP server.

## Start Here

- [README.md](README.md) — project overview, install, core concepts
- [docs/getting-started.md](docs/getting-started.md) — 5-minute setup (`create_llm`, `generate`)
- [docs/prerequisites.md](docs/prerequisites.md) — API keys + local provider setup (Ollama/LMStudio/etc)
- [docs/api-reference.md](docs/api-reference.md) — Python API reference (sync/async, streaming)
- [docs/examples.md](docs/examples.md) — copy/paste examples (tools, streaming, sessions)

## Provider IDs (Factory Names)

- Cloud: `openai`, `anthropic`, `openrouter`
- Local / self-hosted: `ollama`, `lmstudio`, `mlx`, `huggingface`, `vllm`, `openai-compatible`

## Configuration

- [docs/centralized-config.md](docs/centralized-config.md) — defaults + API key management (`OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `OPENROUTER_API_KEY`)
- [abstractcore/providers/registry.py](abstractcore/providers/registry.py) — single source of truth for providers + default models

## Tools & Tool Syntax

- [docs/tool-calling.md](docs/tool-calling.md) — `@tool`, `GenerateResponse.tool_calls`, passthrough vs execution
- [docs/tool-syntax-rewriting.md](docs/tool-syntax-rewriting.md) — `tool_call_tags` (Python) + `agent_format` (server)
- [abstractcore/tools/parser.py](abstractcore/tools/parser.py) — tool-call detection/parsing (tags + JSON-ish)
- [abstractcore/providers/streaming.py](abstractcore/providers/streaming.py) — unified streaming + incremental tool-call parsing
- [docs/mcp.md](docs/mcp.md) — MCP tool servers (HTTP/stdio) as tool sources

## Media & Vision (Input)

- [docs/media-handling-system.md](docs/media-handling-system.md) — universal file attachments + vision fallback
- [docs/vision-capabilities.md](docs/vision-capabilities.md) — vision support overview

## Observability

- [docs/interaction-tracing.md](docs/interaction-tracing.md) — capture prompts/responses/timing/usage for debugging & compliance
- [docs/api-reference.md](docs/api-reference.md) — events (`EventType`, `on_global`, `emit_global`)
- [docs/architecture.md](docs/architecture.md) — high-level system overview

## Thinking / Reasoning

- `thinking`: `None|"auto"|"on"|"off"|True|False|"low"|"medium"|"high"` (best-effort; warns when unsupported)
- Reasoning capture: normalized into `GenerateResponse.metadata["reasoning"]` and stripped from `content` when needed (Harmony transcripts, `<think>` tags, wrapper tokens, and `</think>`-only outputs) via `abstractcore/architectures/response_postprocessing.py`

## Server (OpenAI-Compatible REST API)

- [docs/server.md](docs/server.md) — endpoints + request fields (`base_url`, `agent_format`)
- [abstractcore/server/app.py](abstractcore/server/app.py) — FastAPI implementation

## CLI

- [docs/acore-cli.md](docs/acore-cli.md) — interactive CLI usage
- [abstractcore/utils/cli.py](abstractcore/utils/cli.py) — CLI entrypoint + flags (`--base-url`, `--max-output-tokens`, `/max-tokens`, `/thinking`, `/show-reasoning`)

## Full Context

- [llms-full.txt](llms-full.txt) — standalone, copy/pasteable “full context” file (no required external doc fetches)
