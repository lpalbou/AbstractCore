# Acknowledgements

AbstractCore is made possible by the incredible work of open-source communities, library developers, and AI researchers worldwide. We are grateful to all contributors and maintainers of the following projects and communities.

## Core Dependencies

### Python Infrastructure
- **[Python Software Foundation](https://python.org)** - The Python programming language and ecosystem
- **[Pydantic](https://github.com/pydantic/pydantic)** - Data validation and parsing with Python type hints
- **[httpx](https://github.com/encode/httpx)** - Next-generation HTTP client for Python
- **[tiktoken](https://github.com/openai/tiktoken)** - Fast BPE tokeniser for use with OpenAI's models

### Provider SDK Dependencies
- **[OpenAI Python SDK](https://github.com/openai/openai-python)** - Official OpenAI API client
- **[Anthropic SDK](https://github.com/anthropics/anthropic-sdk-python)** - Official Anthropic API client
- **[Transformers](https://github.com/huggingface/transformers)** - State-of-the-art Machine Learning for PyTorch and TensorFlow
- **[PyTorch](https://github.com/pytorch/pytorch)** - Tensors and Dynamic neural networks in Python
- **[MLX](https://github.com/ml-explore/mlx)** - Array framework for Apple Silicon
- **[sentence-transformers](https://github.com/UKPLab/sentence-transformers)** - SOTA sentence, text and image embeddings
- **[llama-cpp-python](https://github.com/abetlen/llama-cpp-python)** - Python bindings for llama.cpp with native structured output support
- **[Outlines](https://github.com/dottxt-ai/outlines)** - Structured text generation with constrained decoding for LLMs

### Testing and Development
- **[pytest](https://github.com/pytest-dev/pytest)** - The pytest framework makes it easy to write small tests

## LLM Provider Communities

### OpenAI
- OpenAI team for GPT models and the OpenAI API platform
- The OpenAI Developer Community for feedback and improvements

### Anthropic
- Anthropic team for Claude models and the Anthropic API
- Researchers working on AI safety and alignment

### Local Model Ecosystems
- **[Ollama](https://github.com/ollama/ollama)** - Get up and running with large language models locally
- **[LM Studio](https://lmstudio.ai)** - Discover, download, and run local LLMs
- **[Apple MLX Team](https://github.com/ml-explore)** - ML framework for Apple Silicon

### HuggingFace Ecosystem
- **[HuggingFace Team](https://huggingface.co)** - The AI community building the future
- **[Model Contributors](https://huggingface.co/models)** - Thousands of contributors sharing open-source models
- **[Dataset Contributors](https://huggingface.co/datasets)** - Contributors providing training data and benchmarks

## Open Source LLM Communities

### Model Developers and Organizations
- **[Meta AI](https://github.com/facebookresearch)** - Llama family models and research
- **[Mistral AI](https://github.com/mistralai)** - Mistral and Mixtral model families
- **[Qwen Team (Alibaba)](https://github.com/QwenLM)** - Qwen series models including Qwen2.5-Coder and Qwen3-Coder
- **[Google Research](https://github.com/google-research)** - Gemma models and research contributions
- **[BigCode Project](https://github.com/bigcode-project)** - Code generation models like StarCoder
- **[Technology Innovation Institute](https://github.com/tiiuae)** - Falcon model series
- **[EleutherAI](https://github.com/EleutherAI)** - GPT-J, GPT-NeoX, and Pythia models
- **[Stability AI](https://github.com/Stability-AI)** - Stable LM and other generative models

### Embedding Model Contributors
- **[Google Research](https://github.com/google-research)** - EmbeddingGemma and universal embeddings research
- **[IBM Research](https://github.com/ibm)** - Granite embedding models
- **[Nomic AI](https://github.com/nomic-ai)** - nomic-embed models and research
- **[Mixedbread AI](https://github.com/mixedbread-ai)** - MTEB leaderboard and evaluation
- **[UKP Lab](https://github.com/UKPLab)** - Sentence-BERT and sentence-transformers framework

### Model Quantization and Optimization
- **[GGML Community](https://github.com/ggerganov/ggml)** - Efficient tensor operations and model formats
- **[llama.cpp](https://github.com/ggerganov/llama.cpp)** - Fast LLM inference in C++
- **[ONNX Community](https://github.com/onnx/onnx)** - Open Neural Network Exchange format
- **[bitsandbytes](https://github.com/TimDettmers/bitsandbytes)** - 8-bit and 4-bit quantization

## Research and Benchmarking Communities

### Evaluation and Benchmarks
- **[HELM Stanford](https://github.com/stanford-crfm/helm)** - Holistic Evaluation of Language Models
- **[EleutherAI LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)** - Framework for evaluating autoregressive language models
- **[Chatbot Arena (LMSYS)](https://github.com/lm-sys/FastChat)** - Open platform for evaluating LLMs through crowdsourcing
- **[MTEB](https://github.com/embeddings-benchmark/mteb)** - Massive Text Embedding Benchmark

### Architecture and Training Research
- **[Attention Is All You Need Authors](https://arxiv.org/abs/1706.03762)** - Vaswani et al. for the Transformer architecture
- **[GPT Paper Authors](https://openai.com/research/)** - Radford et al. for the GPT architecture
- **[BERT Paper Authors](https://arxiv.org/abs/1810.04805)** - Devlin et al. for bidirectional representations
- **[Chain-of-Thought Reasoning Authors](https://arxiv.org/abs/2201.11903)** - Wei et al. for reasoning improvements
- **[Tool Learning Research Community](https://arxiv.org/abs/2304.08354)** - Researchers advancing tool-augmented language models

## Infrastructure and Standards

### API and Protocol Standards
- **[OpenAPI Initiative](https://www.openapis.org)** - API specification standards
- **[JSON Schema](https://json-schema.org)** - Schema validation for JSON data
- **[OpenTelemetry](https://opentelemetry.io)** - Observability standards and protocols

### Cloud and Deployment
- **[Docker](https://github.com/docker)** - Containerization platform
- **[NVIDIA](https://github.com/NVIDIA)** - CUDA and GPU computing infrastructure
- **[Apple](https://developer.apple.com/metal/)** - Metal Performance Shaders for Apple Silicon

## Package Management and Distribution

### Python Packaging
- **[Python Package Index (PyPI)](https://pypi.org)** - Repository of software for Python
- **[setuptools](https://github.com/pypa/setuptools)** - Build system for Python packages
- **[pip](https://github.com/pypa/pip)** - Package installer for Python

## Special Recognition

### Open Source Philosophy
We are particularly grateful to the broader open-source community that believes in:
- **Transparency** - Making AI models and research accessible to all
- **Collaboration** - Building better AI through shared knowledge
- **Democratization** - Ensuring AI benefits everyone, not just large corporations
- **Innovation** - Pushing the boundaries of what's possible through collective effort

### Educational Resources
- **[Papers with Code](https://paperswithcode.com)** - Making machine learning research accessible
- **[Towards Data Science](https://towardsdatascience.com)** - Medium publication for data science content
- **[Distill.pub](https://distill.pub)** - Clear explanations of machine learning concepts

### Community Platforms
- **[GitHub](https://github.com)** - Platform enabling worldwide collaboration
- **[Discord AI Communities](https://discord.com)** - Real-time collaboration and support
- **[Reddit ML Communities](https://reddit.com/r/MachineLearning)** - Discussion and knowledge sharing
- **[Stack Overflow](https://stackoverflow.com)** - Technical question and answer platform

---

AbstractCore exists because of the collective effort of thousands of researchers, engineers, and enthusiasts who choose to share their work openly. Their contributions make advanced AI capabilities accessible to developers and researchers worldwide.

**Thank you to everyone who contributes to the open-source AI ecosystem.** üôè